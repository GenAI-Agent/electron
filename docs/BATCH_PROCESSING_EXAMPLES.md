# 🚀 智能批次處理實際使用範例

## 📋 Supervisor Agent 如何自動處理大量數據

### 範例1: 處理1000筆客戶資料

**用戶輸入**:
```
"我有一個包含1000筆客戶資料的CSV文件，請幫我分析每個客戶的購買模式，並生成分類報告"
```

**Agent 自動執行流程**:

#### 1. 任務識別
```
Supervisor Agent 分析用戶需求:
- 檢測到 "1000筆" → 大量數據處理
- 檢測到 "每個客戶" → 需要逐項處理  
- 檢測到 "分析" + "分類" → 複雜處理邏輯
→ 決定使用 smart_batch_processor_tool
```

#### 2. 自動調用工具
```python
# Agent 自動生成的工具調用
await smart_batch_processor_tool(
    session_id="user_session_123",
    task_description="分析客戶購買模式並分類",
    data_items=customer_data_list,  # 1000筆客戶資料
    processing_instruction="分析每個客戶的購買頻率、偏好商品類別、消費金額，並進行客戶分類",
    batch_size=50  # 每批處理50筆
)
```

#### 3. 自動批次處理
```
批次 1/20: 處理客戶 1-50
├── 分析購買頻率 → 高頻:15, 中頻:20, 低頻:15
├── 分析商品偏好 → 電子:25, 服飾:15, 家居:10
├── 計算消費金額 → 高消費:10, 中消費:25, 低消費:15
└── 保存到 tmp: batch_1_results

批次 2/20: 處理客戶 51-100
├── 繼續分析...
├── 累積結果...
└── 保存到 tmp: batch_2_results + accumulated_results

... (自動處理剩餘18個批次)

批次 20/20: 處理客戶 951-1000
├── 完成最後批次
├── 生成最終報告
└── 保存完整結果
```

#### 4. 最終回應
```
✅ 批次處理完成！成功處理 985/1000 項目 (98.5%)

📊 客戶分析結果:
- 高頻購買客戶: 300人 (30.5%)
- 中頻購買客戶: 450人 (45.7%) 
- 低頻購買客戶: 235人 (23.9%)

🛍️ 商品偏好分布:
- 電子產品: 400人 (40.6%)
- 服飾類: 350人 (35.5%)
- 家居用品: 235人 (23.9%)

💰 消費水平:
- 高消費 (>5000): 150人 (15.2%)
- 中消費 (1000-5000): 500人 (50.8%)
- 低消費 (<1000): 335人 (34.0%)

📈 建議創建圖表來可視化這些結果嗎？
```

---

### 範例2: 處理大量文件

**用戶輸入**:
```
"幫我處理這500個PDF文件，提取每個文件的關鍵信息並按主題分類"
```

**Agent 執行流程**:

#### 1. 自動工具調用
```python
await smart_batch_processor_tool(
    session_id="user_session_456",
    task_description="PDF文件關鍵信息提取和主題分類",
    data_items=pdf_file_list,  # 500個PDF文件路徑
    processing_instruction="讀取PDF內容，提取關鍵詞和摘要，根據內容進行主題分類",
    batch_size=25  # 每批處理25個文件
)
```

#### 2. 每批次處理邏輯
```
批次 1/20: 處理文件 1-25
├── 讀取PDF內容
├── 提取關鍵詞 → ["AI", "機器學習", "深度學習"]
├── 生成摘要 → "本文討論了AI在醫療領域的應用..."
├── 主題分類 → "人工智能-醫療應用"
└── 保存結果到 tmp

批次 2/20: 處理文件 26-50
├── 繼續處理...
├── 累積分類統計
└── 更新主題分布

... (自動處理剩餘批次)
```

#### 3. 最終統計報告
```
✅ 文件處理完成！成功處理 495/500 個文件 (99.0%)

📂 主題分類結果:
- 人工智能: 120個文件 (24.2%)
- 數據科學: 95個文件 (19.2%)
- 軟體開發: 85個文件 (17.2%)
- 商業分析: 75個文件 (15.2%)
- 其他: 120個文件 (24.2%)

🔍 高頻關鍵詞:
- "機器學習": 出現在 180個文件中
- "數據分析": 出現在 150個文件中
- "人工智能": 出現在 140個文件中

📊 處理統計:
- 平均處理時間: 2.3秒/文件
- 總處理時間: 19分鐘
- 錯誤文件: 5個 (格式問題)
```

---

### 範例3: 數據清理和轉換

**用戶輸入**:
```
"這個數據庫有2000筆記錄，很多數據不完整或有錯誤，請幫我清理並標準化"
```

**Agent 執行流程**:

#### 1. 智能批次處理
```python
await smart_batch_processor_tool(
    session_id="user_session_789",
    task_description="數據清理和標準化",
    data_items=database_records,  # 2000筆記錄
    processing_instruction="檢查數據完整性，修正格式錯誤，填補缺失值，標準化格式",
    batch_size=100  # 每批處理100筆
)
```

#### 2. 清理過程
```
批次 1/20: 處理記錄 1-100
├── 檢查必填欄位 → 發現15筆缺失
├── 修正日期格式 → 統一為 YYYY-MM-DD
├── 標準化電話號碼 → 統一為 +886-XXX-XXXXXX
├── 填補缺失值 → 使用預設值或推算值
└── 清理結果: 85筆完整, 15筆需人工確認

批次 2/20: 處理記錄 101-200
├── 繼續清理...
├── 累積統計...
└── 更新清理報告

... (自動處理剩餘批次)
```

#### 3. 清理報告
```
✅ 數據清理完成！處理 2000 筆記錄

🧹 清理統計:
- 完全清理: 1650筆 (82.5%)
- 部分清理: 280筆 (14.0%)
- 需人工處理: 70筆 (3.5%)

🔧 修正項目:
- 日期格式標準化: 450筆
- 電話號碼格式化: 320筆
- 郵件地址驗證: 180筆
- 缺失值填補: 220筆

📊 數據品質提升:
- 完整性: 65% → 96.5%
- 一致性: 70% → 98.2%
- 準確性: 85% → 94.8%
```

---

## 🔧 技術實現細節

### 1. 自動狀態管理
```python
# 每批次處理後自動保存狀態
{
    "batch_number": 5,
    "total_processed": 250,
    "completion_percentage": 25.0,
    "success_count": 245,
    "error_count": 5,
    "accumulated_results": [...],
    "next_batch_start": 251
}
```

### 2. 中間結果累積
```python
# tmp 空間中的數據結構
/task_memory/sessions/{session_id}/temp_data/
├── batch_1_results.json      # 第1批次結果
├── batch_2_results.json      # 第2批次結果
├── ...
├── accumulated_results.json  # 累積結果
└── final_report.json         # 最終報告
```

### 3. 錯誤恢復機制
```python
# 如果某批次失敗，不影響整體任務
if batch_error:
    save_error_log(batch_number, error_details)
    continue_next_batch()
    
# 任務可以從任意批次恢復
resume_from_batch(last_successful_batch + 1)
```

---

## 🎯 使用建議

### 何時使用智能批次處理
- ✅ 數據量 > 100 項
- ✅ 需要對每項數據進行複雜處理
- ✅ 處理時間較長（>5分鐘）
- ✅ 需要中間結果保存
- ✅ 可能需要暫停/恢復

### 最佳實踐
1. **合適的批次大小**: 
   - 簡單處理: 100-200項/批次
   - 複雜處理: 20-50項/批次
   - 文件處理: 10-25個文件/批次

2. **清晰的處理指令**:
   - 具體說明每項數據需要什麼處理
   - 包含預期的輸出格式
   - 指定錯誤處理方式

3. **監控和調試**:
   - 使用 get_batch_processing_status_tool 查看進度
   - 檢查 tmp 空間中的中間結果
   - 關注錯誤日誌和失敗項目

這就是 Supervisor Agent 如何智能地處理大量數據的完整流程！
