"""
Supervisor Agent - Gmail è‡ªå‹•åŒ–è™•ç†ç›£ç£è€…
ä½¿ç”¨ LangGraph æ¶æ§‹ï¼Œæ•´åˆå¤šå€‹å°ˆæ¥­å·¥å…·ï¼Œæä¾› Gmail è‡ªå‹•åŒ–è™•ç†åŠŸèƒ½
åƒè€ƒ example/gov_agent.py çš„æ¶æ§‹å¯¦ç¾
"""

from __future__ import annotations
import logging
import asyncio
import json
import time
import uuid
import os
import sys
from typing import List, Optional, Dict, Any, Annotated, Literal
from typing_extensions import TypedDict
from dotenv import load_dotenv

# from langchain.callbacks.tracers import LangChainTracer
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.prebuilt.tool_node import ToolNode as BaseToolNode
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool
from langchain_openai import AzureChatOpenAI
import tiktoken

# å·¥å…·å°‡åœ¨æŸ¥è©¢æ™‚å‹•æ…‹å°å…¥

from ..utils.logger import get_logger

logger = get_logger(__name__)
load_dotenv()
# ----------------------- State Definition ----------------------- #


class SupervisorAgentState(TypedDict):
    """Supervisor Agent çš„ç‹€æ…‹å®šç¾©"""

    messages: Annotated[list, add_messages]
    query: str
    rule_id: Optional[str]
    context: Optional[Dict[str, Any]]


# ----------------------- å¹³è¡Œå·¥å…·åŸ·è¡Œç¯€é» ----------------------- #


class ParallelToolNode(BaseToolNode):
    """å¹³è¡ŒåŸ·è¡Œå·¥å…·çš„è‡ªå®šç¾© ToolNode"""

    def __init__(self, tools: List, stream_callback=None):
        super().__init__(tools)
        self.tools_by_name = {tool.name: tool for tool in tools}
        self.stream_callback = stream_callback  # æ·»åŠ streamå›èª¿å‡½æ•¸

    async def _execute_single_tool_with_message(
        self, tool, tool_args, tool_call_id, tool_name
    ):
        """åŸ·è¡Œå–®å€‹å·¥å…·ä¸¦è¿”å› ToolMessage"""
        try:
            # è¨˜éŒ„å·¥å…·èª¿ç”¨åƒæ•¸
            logger.info(f"ğŸ”§ åŸ·è¡Œå·¥å…·: {tool_name}")
            logger.info(f"ğŸ“‹ å·¥å…·åƒæ•¸: {tool_args}")
            start_time = time.time()

            # åŸ·è¡Œå·¥å…·
            if asyncio.iscoroutinefunction(tool.func):
                result = await tool.func(**tool_args)
            else:
                result = tool.func(**tool_args)

            execution_time = time.time() - start_time
            logger.info(f"âœ… å·¥å…· {tool_name} åŸ·è¡Œå®Œæˆï¼Œè€—æ™‚ {execution_time:.2f}ç§’")

            # è¨˜éŒ„å·¥å…·åŸ·è¡Œçµæœï¼ˆå‰300å­—ç¬¦ï¼‰
            result_str = str(result)
            logger.info(f"ğŸ“¤ å·¥å…· {tool_name} åŸ·è¡Œçµæœå‰300å­—ç¬¦: {result_str[:300]}")

            # åŒ…è£å·¥å…·çµæœï¼Œæ·»åŠ  tool æ¨™ç±¤
            wrapped_result = f"<tool name='{tool_name}' execution_time='{execution_time:.2f}s'>\n{result_str}\n</tool>"

            # å¦‚æœæœ‰streamå›èª¿ï¼Œå¯¦æ™‚ç™¼é€å·¥å…·åŸ·è¡Œçµæœ
            if self.stream_callback:
                await self.stream_callback(
                    {
                        "type": "tool_result",
                        "tool_name": tool_name,
                        "parameters": tool_args,
                        "result": result_str,
                        "execution_time": execution_time,
                        "wrapped_result": wrapped_result,
                    }
                )

            # å‰µå»º ToolMessage
            return ToolMessage(
                content=wrapped_result, tool_call_id=tool_call_id, name=tool_name
            )

        except Exception as e:
            logger.error(f"âŒ å·¥å…· {tool_name} åŸ·è¡Œå¤±æ•—: {e}")
            error_result = f"<tool name='{tool_name}' status='error'>\nå·¥å…·åŸ·è¡Œå¤±æ•—: {str(e)}\n</tool>"
            return ToolMessage(
                content=error_result, tool_call_id=tool_call_id, name=tool_name
            )

    async def __call__(self, state: SupervisorAgentState) -> Dict[str, Any]:
        """å¹³è¡ŒåŸ·è¡Œæ‰€æœ‰å·¥å…·èª¿ç”¨"""
        messages = state.get("messages", [])

        # æ‰¾åˆ°æœ€å¾Œä¸€å€‹ AI æ¶ˆæ¯ä¸­çš„å·¥å…·èª¿ç”¨
        tool_calls = []
        for message in reversed(messages):
            if (
                isinstance(message, AIMessage)
                and hasattr(message, "tool_calls")
                and message.tool_calls
            ):
                tool_calls = message.tool_calls
                # èª¿è©¦æ—¥èªŒï¼šæª¢æŸ¥åŸå§‹ tool_calls
                logger.info(f"ğŸ” æ‰¾åˆ° AI æ¶ˆæ¯çš„ tool_calls: {tool_calls}")
                break

        if not tool_calls:
            logger.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°å·¥å…·èª¿ç”¨")
            return {"messages": []}

        logger.info(f"ğŸš€ å¹³è¡ŒåŸ·è¡Œ {len(tool_calls)} å€‹å·¥å…·")

        # æº–å‚™å¹³è¡ŒåŸ·è¡Œçš„ä»»å‹™
        tasks = []
        for tool_call in tool_calls:
            tool_name = tool_call["name"]
            tool_args = tool_call.get("args", {})
            tool_call_id = tool_call.get("id", "")

            # èª¿è©¦æ—¥èªŒï¼šæª¢æŸ¥ tool_call_id
            logger.info(
                f"ğŸ” å·¥å…·èª¿ç”¨è©³æƒ…: name={tool_name}, id={tool_call_id}, args={tool_args}"
            )

            if tool_name in self.tools_by_name:
                tool = self.tools_by_name[tool_name]

                # å‰µå»ºç•°æ­¥ä»»å‹™
                task = self._execute_single_tool_with_message(
                    tool, tool_args, tool_call_id, tool_name
                )
                tasks.append(task)
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥å·¥å…·: {tool_name}")

        if not tasks:
            return {"messages": []}

        # å¹³è¡ŒåŸ·è¡Œæ‰€æœ‰å·¥å…·
        try:
            tool_messages = await asyncio.gather(*tasks, return_exceptions=True)

            # è™•ç†çµæœ
            valid_messages = []
            for msg in tool_messages:
                if isinstance(msg, ToolMessage):
                    valid_messages.append(msg)
                elif isinstance(msg, Exception):
                    logger.error(f"âŒ å·¥å…·åŸ·è¡Œç•°å¸¸: {msg}")

            logger.info(f"âœ… å¹³è¡Œå·¥å…·åŸ·è¡Œå®Œæˆï¼ŒæˆåŠŸ {len(valid_messages)} å€‹")
            return {"messages": valid_messages}

        except Exception as e:
            logger.error(f"âŒ å¹³è¡Œå·¥å…·åŸ·è¡Œå¤±æ•—: {e}")
            return {"messages": []}


# ----------------------- Supervisor Agent ----------------------- #


class SupervisorAgent:
    """Gmail è‡ªå‹•åŒ–è™•ç†ç›£ç£è€… Agent"""

    def __init__(self, rules_dir: str = "data/rules", stream_callback=None):
        logger.info("ğŸ”„ é–‹å§‹åˆå§‹åŒ– Supervisor Agent...")
        init_start = time.time()

        # è¨­ç½®è¦å‰‡ç›®éŒ„
        self.rules_dir = rules_dir
        # è¨­ç½®streamå›èª¿å‡½æ•¸
        self.stream_callback = stream_callback
        # self.tracer = LangChainTracer(project_name="BI-supervisor-agent")
        # åˆå§‹åŒ– LLM
        self.llm = AzureChatOpenAI(
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            azure_deployment="gpt-4o",
            api_version="2025-01-01-preview",
            temperature=0.7,
        )

        logger.info("âœ… LLM åˆå§‹åŒ–å®Œæˆ")

        # åˆå§‹åŒ–Tokenè¨ˆç®—å™¨
        try:
            self.tokenizer = tiktoken.encoding_for_model("gpt-4")
        except:
            self.tokenizer = tiktoken.get_encoding("cl100k_base")

        # ç•¶å‰æœƒè©±çš„å·¥å…·ï¼ˆå‹•æ…‹è¨­ç½®ï¼‰
        self.current_tools = []
        self.current_llm_with_tools = None
        self.current_graph = None

        init_time = time.time() - init_start
        logger.info(f"âœ… Supervisor Agent åˆå§‹åŒ–å®Œæˆï¼Œè€—æ™‚ {init_time:.2f}ç§’")

    def calculate_tokens(self, text: str) -> int:
        """è¨ˆç®—æ–‡æœ¬çš„tokenæ•¸é‡"""
        try:
            return len(self.tokenizer.encode(text))
        except Exception as e:
            logger.warning(f"Tokenè¨ˆç®—å¤±æ•—: {e}")
            # ç°¡å–®ä¼°ç®—ï¼š1 token â‰ˆ 4 å­—ç¬¦
            return len(text) // 4

    def calculate_messages_tokens(self, messages: List) -> int:
        """è¨ˆç®—æ¶ˆæ¯åˆ—è¡¨çš„ç¸½tokenæ•¸"""
        total_tokens = 0
        for msg in messages:
            if hasattr(msg, "content"):
                total_tokens += self.calculate_tokens(str(msg.content))
            else:
                total_tokens += self.calculate_tokens(str(msg))
        return total_tokens

    def manage_context_for_batch_processing(
        self, messages: List, context: Dict[str, Any]
    ) -> List:
        """ç‚ºbatch processingç®¡ç†ä¸Šä¸‹æ–‡ï¼Œåªä¿ç•™é€²åº¦ä¿¡æ¯"""
        is_batch_mode = context.get("is_batch_processing", False)

        if not is_batch_mode:
            return messages  # ébatchæ¨¡å¼ï¼Œä¿æŒåŸæœ‰é‚è¼¯

        # Batchæ¨¡å¼ï¼šåªä¿ç•™æœ€è¿‘çš„é‡è¦æ¶ˆæ¯å’Œé€²åº¦ä¿¡æ¯
        important_messages = []
        tool_call_count = 0

        for msg in messages:
            if isinstance(msg, (HumanMessage, SystemMessage)):
                # ä¿ç•™ç”¨æˆ¶æ¶ˆæ¯å’Œç³»çµ±æ¶ˆæ¯
                important_messages.append(msg)
            elif isinstance(msg, AIMessage):
                # ä¿ç•™AIæ¶ˆæ¯ï¼Œä½†ç°¡åŒ–å…§å®¹
                if hasattr(msg, "tool_calls") and msg.tool_calls:
                    tool_call_count += len(msg.tool_calls)
                important_messages.append(msg)
            elif isinstance(msg, ToolMessage):
                # å·¥å…·æ¶ˆæ¯åªä¿ç•™é€²åº¦ä¿¡æ¯ï¼Œä¸ä¿ç•™è©³ç´°çµæœ
                tool_call_count += 1

                # æª¢æŸ¥æ˜¯å¦æ˜¯é€²åº¦ç›¸é—œçš„å·¥å…·çµæœ
                content = str(msg.content)
                if any(
                    keyword in content.lower()
                    for keyword in ["é€²åº¦", "progress", "å®Œæˆ", "ä»»å‹™", "task"]
                ):
                    # ä¿ç•™é€²åº¦ä¿¡æ¯
                    important_messages.append(msg)
                else:
                    # ç°¡åŒ–å·¥å…·çµæœ
                    simplified_content = (
                        f"å·¥å…· {msg.name} åŸ·è¡Œå®Œæˆ (ç¬¬{tool_call_count}æ¬¡èª¿ç”¨)"
                    )
                    simplified_msg = ToolMessage(
                        content=simplified_content,
                        tool_call_id=msg.tool_call_id,
                        name=msg.name,
                    )
                    important_messages.append(simplified_msg)

        # è¨˜éŒ„tokenç¯€çœæƒ…æ³
        original_tokens = self.calculate_messages_tokens(messages)
        managed_tokens = self.calculate_messages_tokens(important_messages)
        logger.info(
            f"ğŸ§  Batchæ¨¡å¼Tokenç®¡ç†: {original_tokens} â†’ {managed_tokens} (ç¯€çœ {original_tokens - managed_tokens})"
        )

        return important_messages

    def compress_tool_messages(self, messages: List, max_tool_results: int = 3) -> List:
        """
        æ”¹é€²çš„å·¥å…·æ¶ˆæ¯å£“ç¸®æ–¹æ³•
        - ä¿ç•™å®Œæ•´çš„ SystemMessage å’Œ HumanMessage
        - ä¿ç•™æœ€æ–°ä¸€å€‹ tool result çš„å®Œæ•´å…§å®¹
        - å£“ç¸®ä¸­é–“çš„ tool results æˆçµæ§‹åŒ–æ‘˜è¦
        - é‡è¦ä¿¡æ¯ï¼ˆå¦‚æ–‡ä»¶è·¯å¾‘ï¼‰å®Œæ•´ä¿ç•™

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            max_tool_results: æœ€å¤§ä¿ç•™çš„å·¥å…·çµæœæ•¸é‡

        Returns:
            å£“ç¸®å¾Œçš„æ¶ˆæ¯åˆ—è¡¨
        """
        # è¿½è¹¤å£“ç¸®æ¬¡æ•¸
        if not hasattr(self, "_compression_count"):
            self._compression_count = 0
        self._compression_count += 1

        # åˆ†é¡æ¶ˆæ¯
        system_messages = []
        human_messages = []
        ai_messages = []
        tool_messages = []

        for msg in messages:
            if isinstance(msg, SystemMessage):
                system_messages.append(msg)
            elif isinstance(msg, HumanMessage):
                human_messages.append(msg)
            elif isinstance(msg, AIMessage):
                ai_messages.append(msg)
            elif isinstance(msg, ToolMessage):
                tool_messages.append(msg)

        # å¦‚æœæ²’æœ‰å·¥å…·æ¶ˆæ¯ï¼Œç›´æ¥è¿”å›åŸæ¶ˆæ¯
        if not tool_messages:
            return messages

        # æ§‹å»ºå£“ç¸®å¾Œçš„æ¶ˆæ¯åˆ—è¡¨
        compressed_messages = []

        # 1. ä¿ç•™å®Œæ•´çš„ç³»çµ±æ¶ˆæ¯å’Œç”¨æˆ¶æ¶ˆæ¯
        compressed_messages.extend(system_messages)
        compressed_messages.extend(human_messages)

        # 2. ä¿ç•™æœ€è¿‘çš„ AI æ¶ˆæ¯
        if ai_messages:
            # ä¿ç•™æœ€å¾Œä¸€å€‹ AI æ¶ˆæ¯
            compressed_messages.append(ai_messages[-1])

        # 3. è™•ç†å·¥å…·æ¶ˆæ¯
        if len(tool_messages) <= max_tool_results:
            # å¦‚æœå·¥å…·æ¶ˆæ¯æ•¸é‡ä¸å¤šï¼Œç›´æ¥ä¿ç•™
            compressed_messages.extend(tool_messages)
        else:
            # éœ€è¦å£“ç¸®ï¼šä¿ç•™æœ€æ–°ä¸€å€‹å®Œæ•´ï¼Œå£“ç¸®å…¶ä»–
            latest_tool = tool_messages[-1]  # æœ€æ–°çš„å·¥å…·çµæœ
            middle_tools = tool_messages[:-1]  # ä¸­é–“çš„å·¥å…·çµæœ

            # å‰µå»ºå£“ç¸®æ‘˜è¦
            compression_summary = self._create_compression_summary(middle_tools)

            # å°‡å£“ç¸®æ‘˜è¦ä½œç‚º SystemMessage æ’å…¥ï¼ˆé¿å… tool_call_id é©—è­‰å•é¡Œï¼‰
            compression_system_msg = SystemMessage(
                content=f"ğŸ“‹ è¨˜æ†¶å£“ç¸®æ‘˜è¦:\n{compression_summary}"
            )

            # æ·»åŠ å£“ç¸®æ‘˜è¦å’Œæœ€æ–°å·¥å…·çµæœ
            compressed_messages.append(compression_system_msg)
            compressed_messages.append(latest_tool)

        return compressed_messages

    def _create_compression_summary(self, tool_messages: List) -> str:
        """
        å‰µå»ºå·¥å…·æ¶ˆæ¯çš„å£“ç¸®æ‘˜è¦

        Args:
            tool_messages: è¦å£“ç¸®çš„å·¥å…·æ¶ˆæ¯åˆ—è¡¨

        Returns:
            çµæ§‹åŒ–çš„å£“ç¸®æ‘˜è¦å­—ç¬¦ä¸²
        """
        import json
        from datetime import datetime

        summary_parts = [
            f"ğŸ§  ç¬¬ {self._compression_count} æ¬¡è¨˜æ†¶å£“ç¸®",
            f"ğŸ“Š å£“ç¸®æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"ğŸ“‹ åŸå§‹å·¥å…·æ¶ˆæ¯æ•¸: {len(tool_messages)}",
            "",
            "ğŸ“ å·¥å…·åŸ·è¡Œæ‘˜è¦:",
        ]

        for i, tool_msg in enumerate(tool_messages, 1):
            tool_name = tool_msg.name
            content = str(tool_msg.content)

            # æå–é‡è¦å…§å®¹
            important_info = self._extract_important_content(content, tool_name)

            summary_parts.extend(
                [
                    f"",
                    f"ç¬¬{i}å€‹ tool: {tool_name}",
                    f"toolè£¡é¢çš„é‡è¦å…§å®¹:",
                    important_info,
                    "---",
                ]
            )

        summary_parts.extend(
            [
                "",
                "ğŸ’¡ æ³¨æ„: ä»¥ä¸Šç‚ºå£“ç¸®æ‘˜è¦ï¼Œæœ€æ–°çš„å·¥å…·çµæœä¿æŒå®Œæ•´ã€‚",
                "ğŸ”„ å¦‚éœ€è©³ç´°ä¿¡æ¯ï¼Œè«‹åƒè€ƒæœ€æ–°çš„å·¥å…·åŸ·è¡Œçµæœã€‚",
            ]
        )

        return "\n".join(summary_parts)

    def _extract_important_content(self, content: str, tool_name: str) -> str:
        """
        å¾å·¥å…·çµæœä¸­æå–é‡è¦å…§å®¹

        Args:
            content: å·¥å…·çµæœå…§å®¹
            tool_name: å·¥å…·åç¨±

        Returns:
            æå–çš„é‡è¦å…§å®¹
        """
        try:
            import json

            # å˜—è©¦è§£æ JSON å…§å®¹
            if content.startswith("<tool") and content.endswith("</tool>"):
                # æå– XML æ¨™ç±¤å…§çš„å…§å®¹
                start = content.find(">") + 1
                end = content.rfind("<")
                json_content = content[start:end].strip()
            else:
                json_content = content

            parsed = json.loads(json_content)

            if isinstance(parsed, dict):
                important_info = []

                # åŸºæœ¬ç‹€æ…‹ä¿¡æ¯
                if "success" in parsed:
                    status = "âœ… æˆåŠŸ" if parsed["success"] else "âŒ å¤±æ•—"
                    important_info.append(f"åŸ·è¡Œç‹€æ…‹: {status}")

                # éŒ¯èª¤ä¿¡æ¯
                if "error" in parsed and parsed["error"]:
                    important_info.append(f"éŒ¯èª¤ä¿¡æ¯: {parsed['error']}")

                # æ–‡ä»¶è·¯å¾‘ä¿¡æ¯ï¼ˆå®Œæ•´ä¿ç•™ï¼‰
                file_path_keys = [
                    "file_path",
                    "temp_file_path",
                    "current_file",
                    "output_file",
                ]
                for key in file_path_keys:
                    if key in parsed and parsed[key]:
                        important_info.append(f"{key}: {parsed[key]}")

                # æ•¸æ“šçµ±è¨ˆä¿¡æ¯
                stats_keys = [
                    "total_rows",
                    "filtered_rows",
                    "original_rows",
                    "processed_items",
                    "success_count",
                    "error_count",
                ]
                for key in stats_keys:
                    if key in parsed and parsed[key] is not None:
                        important_info.append(f"{key}: {parsed[key]}")

                # æ“ä½œä¿¡æ¯
                operation_keys = ["operation", "analysis_type", "tool_type", "message"]
                for key in operation_keys:
                    if key in parsed and parsed[key]:
                        value = str(parsed[key])
                        if len(value) > 100:
                            value = value[:100] + "..."
                        important_info.append(f"{key}: {value}")

                # çµæœæ‘˜è¦
                if "results" in parsed and isinstance(parsed["results"], dict):
                    results_summary = []
                    for k, v in parsed["results"].items():
                        if isinstance(v, (int, float, str)) and len(str(v)) < 50:
                            results_summary.append(f"{k}: {v}")
                        elif isinstance(v, dict) and "value" in v:
                            results_summary.append(f"{k}: {v['value']}")

                    if results_summary:
                        important_info.append(
                            f"çµæœæ‘˜è¦: {', '.join(results_summary[:5])}"
                        )

                # å¦‚æœæ²’æœ‰æå–åˆ°é‡è¦ä¿¡æ¯ï¼Œä½¿ç”¨æ¶ˆæ¯å…§å®¹
                if not important_info and "message" in parsed:
                    msg = str(parsed["message"])
                    important_info.append(
                        f"æ¶ˆæ¯: {msg[:200]}{'...' if len(msg) > 200 else ''}"
                    )

                return (
                    "\n".join(f"  â€¢ {info}" for info in important_info)
                    if important_info
                    else "  â€¢ ç„¡é‡è¦ä¿¡æ¯æå–"
                )

        except (json.JSONDecodeError, Exception):
            # å¦‚æœä¸æ˜¯ JSON æˆ–è§£æå¤±æ•—ï¼Œæå–å‰200å­—ç¬¦
            clean_content = content.replace("\n", " ").strip()
            if len(clean_content) > 200:
                return f"  â€¢ å…§å®¹æ‘˜è¦: {clean_content[:200]}..."
            else:
                return f"  â€¢ å…§å®¹: {clean_content}"

        return "  â€¢ ç„¡æ³•æå–å…§å®¹"

    def setup_tools_for_query(
        self, tool_names: List[str] = None, available_tools: List = None
    ):
        """ç‚ºç•¶å‰æŸ¥è©¢å‹•æ…‹è¨­ç½®å·¥å…·"""
        logger.info(f"ğŸ”§ é–‹å§‹å‹•æ…‹è¨­ç½®å·¥å…·ï¼Œè¦å‰‡å·¥å…·: {tool_names}")

        # é–‹å§‹è¨­ç½®å·¥å…·
        self.current_tools = []

        # å¦‚æœæœ‰å¤–éƒ¨æä¾›çš„å·¥å…·åˆ—è¡¨ï¼Œå„ªå…ˆä½¿ç”¨
        if available_tools:
            self.current_tools = available_tools
            logger.info(f"ğŸ“ ä½¿ç”¨å¤–éƒ¨æä¾›çš„å·¥å…·ï¼Œå…± {len(available_tools)} å€‹")
            for tool in available_tools:
                tool_name = getattr(tool, "name", str(tool))
                logger.info(f"ğŸ”§ æ·»åŠ å·¥å…·: {tool_name}")
        else:
            # å¦å‰‡ä½¿ç”¨é»˜èªç€è¦½å™¨å·¥å…·ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
            try:
                from ..tools.langchain_browser_tools import get_langchain_browser_tools

                browser_tools = get_langchain_browser_tools()

                for tool in browser_tools:
                    self.current_tools.append(tool)

            except Exception as e:
                logger.warning(f"âš ï¸ ç€è¦½å™¨å·¥å…·å°å…¥å¤±æ•—: {e}")

        # æ ¹æ“šè¦å‰‡æ·»åŠ é¡å¤–å·¥å…·ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if tool_names:
            logger.info(f"ğŸ“‹ è¦å‰‡æŒ‡å®šçš„å·¥å…·: {tool_names}")
            # TODO: é€™è£¡å¯ä»¥æ ¹æ“š tool_names æ·»åŠ é¡å¤–çš„å·¥å…·

        # ç¶å®šå·¥å…·åˆ° LLM
        if self.current_tools:
            self.current_llm_with_tools = self.llm.bind_tools(self.current_tools)
            logger.info(f"ğŸ”§ å·¥å…·ç¶å®šå®Œæˆï¼Œå…± {len(self.current_tools)} å€‹å·¥å…·")
        else:
            self.current_llm_with_tools = self.llm
            logger.info("ğŸ”§ ç„¡å·¥å…·æ¨¡å¼ï¼Œä½¿ç”¨ç´”LLM")

        # é‡æ–°å»ºç«‹ graph
        self._build_graph()

    def _build_graph(self):
        """å»ºç«‹ LangGraph workflow - å¾ªç’°æ±ºç­–æ¶æ§‹"""
        # åˆå§‹åŒ– StateGraph
        workflow = StateGraph(SupervisorAgentState)

        # å‰µå»ºè‡ªå®šç¾©çš„å¹³è¡Œ ToolNode ä¾†è™•ç†å·¥å…·èª¿ç”¨
        if self.current_tools:
            tool_node = ParallelToolNode(self.current_tools, self.stream_callback)
        else:
            # æ²’æœ‰å·¥å…·æ™‚å‰µå»ºä¸€å€‹ç©ºçš„å·¥å…·ç¯€é»
            tool_node = ParallelToolNode([], self.stream_callback)

        # æ·»åŠ ç¯€é»
        workflow.add_node("supervisor", self.supervisor_node)  # ä¸­å¤®æ±ºç­–ç¯€é»
        workflow.add_node("tools", tool_node)  # å·¥å…·åŸ·è¡Œç¯€é»ï¼ˆä½¿ç”¨å¹³è¡ŒåŸ·è¡Œï¼‰
        workflow.add_node(
            "response_generator", self.response_generator_node
        )  # æœ€çµ‚å›ç­”ç”Ÿæˆç¯€é»

        # è¨­å®šæµç¨‹ - å¾supervisorç¯€é»é–‹å§‹
        workflow.add_edge(START, "supervisor")

        # supervisorç¯€é»å¾Œçš„æ¢ä»¶åˆ†æ”¯
        workflow.add_conditional_edges(
            "supervisor",
            self.should_continue,  # è‡ªå®šç¾©æ¢ä»¶å‡½æ•¸
            {
                "tools": "tools",  # éœ€è¦èª¿ç”¨å·¥å…·
                "respond": "response_generator",  # ç›´æ¥å›ç­”
                "__end__": END,  # çµæŸ
            },
        )

        # å·¥å…·åŸ·è¡Œå¾Œå›åˆ°supervisorç¯€é»é‡æ–°è©•ä¼°
        workflow.add_edge("tools", "supervisor")

        # å›ç­”ç”Ÿæˆå¾ŒçµæŸ
        workflow.add_edge("response_generator", END)

        # ç·¨è­¯ graph with çŸ­æœŸè¨˜æ†¶
        self.current_graph = workflow.compile(checkpointer=MemorySaver())

        logger.info(
            f"âœ… Supervisor Agent Graph å»ºç«‹å®Œæˆï¼Œå·¥å…·æ•¸é‡: {len(self.current_tools)}"
        )

    def should_continue(self, state: SupervisorAgentState) -> str:
        """æ±ºå®šä¸‹ä¸€æ­¥å‹•ä½œçš„æ¢ä»¶å‡½æ•¸"""
        messages = state.get("messages", [])
        context = state.get("context", {})

        if not messages:
            return "respond"

        last_message = messages[-1]

        # å¦‚æœæœ€å¾Œä¸€å€‹æ¶ˆæ¯æ˜¯AIæ¶ˆæ¯ä¸”æœ‰å·¥å…·èª¿ç”¨ï¼ŒåŸ·è¡Œå·¥å…·
        if (
            isinstance(last_message, AIMessage)
            and hasattr(last_message, "tool_calls")
            and last_message.tool_calls
        ):
            logger.info(f"ğŸ”§ supervisoræ±ºå®šèª¿ç”¨å·¥å…·: {len(last_message.tool_calls)} å€‹")
            return "tools"

        # æª¢æŸ¥æ˜¯å¦æ˜¯batch processingæ¨¡å¼
        is_batch_mode = context.get("is_batch_processing", False)

        # æª¢æŸ¥æ˜¯å¦é”åˆ°æœ€å¤§å·¥å…·èª¿ç”¨æ¬¡æ•¸ï¼ˆé˜²æ­¢ç„¡é™å¾ªç’°ï¼‰
        tool_messages = [msg for msg in messages if isinstance(msg, ToolMessage)]
        max_tools = 50 if is_batch_mode else 10  # batchæ¨¡å¼å…è¨±æ›´å¤šå·¥å…·èª¿ç”¨

        if len(tool_messages) >= max_tools:
            logger.info(f"ğŸ›‘ é”åˆ°æœ€å¤§å·¥å…·èª¿ç”¨æ¬¡æ•¸({max_tools})ï¼Œå¼·åˆ¶ç”Ÿæˆå›ç­”")
            return "respond"

        # å¦‚æœæœ€å¾Œä¸€å€‹æ¶ˆæ¯æ˜¯AIæ¶ˆæ¯ä½†æ²’æœ‰å·¥å…·èª¿ç”¨ï¼Œç”Ÿæˆæœ€çµ‚å›ç­”
        if isinstance(last_message, AIMessage):
            logger.info("ï¿½ supervisoræ±ºå®šç”Ÿæˆæœ€çµ‚å›ç­”")
            return "respond"

        # å…¶ä»–æƒ…æ³ï¼ˆå¦‚ToolMessageï¼‰ï¼Œèªªæ˜éœ€è¦å›åˆ°supervisoré‡æ–°è©•ä¼°
        # ä½†é€™å€‹é‚è¼¯å·²ç¶“åœ¨graphä¸­è™•ç†äº†ï¼ˆtools -> supervisorï¼‰
        logger.info("ğŸ”„ å…¶ä»–æƒ…æ³ï¼Œç”Ÿæˆå›ç­”")
        return "respond"

    async def supervisor_node(self, state: SupervisorAgentState) -> Dict[str, Any]:
        """ä¸­å¤®æ±ºç­–ç¯€é» - åˆ†æç•¶å‰ç‹€æ…‹ä¸¦æ±ºå®šä¸‹ä¸€æ­¥å‹•ä½œ"""
        query = state.get("query", "")
        messages = state.get("messages", [])
        rule_id = state.get("rule_id")
        context = state.get("context", {})

        # è¨ˆç®—ç•¶å‰tokenä½¿ç”¨é‡
        current_tokens = self.calculate_messages_tokens(messages)
        logger.info(f"ğŸ“Š ç•¶å‰ä¸Šä¸‹æ–‡Tokenæ•¸: {current_tokens}")

        # æ™ºèƒ½è¨˜æ†¶ç®¡ç† - æš«æ™‚ç¦ç”¨ä»¥èª¿è©¦ tool_call_id å•é¡Œ
        if current_tokens > 20000:  # æé«˜é–¾å€¼ï¼Œæš«æ™‚æ¸›å°‘å£“ç¸®
            logger.info(f"ğŸ§  Tokenæ•¸é‡éå¤š ({current_tokens})ï¼Œé–‹å§‹è¨˜æ†¶å£“ç¸®")
            # messages = self.compress_tool_messages(messages, max_tool_results=3)  # æš«æ™‚ç¦ç”¨
            # compressed_tokens = self.calculate_messages_tokens(messages)
            logger.info(f"ğŸ§  è¨˜æ†¶å£“ç¸®å·²æš«æ™‚ç¦ç”¨ä»¥èª¿è©¦ tool_call_id å•é¡Œ")
            # logger.info(
            #     f"ğŸ§  è¨˜æ†¶å£“ç¸®å®Œæˆ: {current_tokens} â†’ {compressed_tokens} (ç¯€çœ {current_tokens - compressed_tokens})"
            # )
            state["messages"] = messages

            # å£“ç¸®å¾Œï¼Œå°‡æœƒè©±ç‹€æ…‹ä¿¡æ¯æ³¨å…¥åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼Œç¢ºä¿ä¸ä¸Ÿå¤±é‡è¦ä¿¡æ¯
            try:
                from ..core.session_data_manager import session_data_manager

                session_summary = session_data_manager.get_session_summary(
                    context.get("session_id", "default")
                )
                if session_summary.get("has_current_data"):
                    context["session_data_info"] = {
                        "current_data_file": session_summary.get("current_data_file"),
                        "operations_count": session_summary.get("operations_count"),
                        "last_operation": session_summary.get("last_operation"),
                        "note": "è¨˜æ†¶å£“ç¸®å¾Œä¿ç•™çš„æœƒè©±æ•¸æ“šç‹€æ…‹ä¿¡æ¯",
                    }
                    logger.info(
                        f"ğŸ”„ æœƒè©±ç‹€æ…‹ä¿¡æ¯å·²æ³¨å…¥ä¸Šä¸‹æ–‡: {session_summary.get('current_data_file')}"
                    )
            except Exception as e:
                logger.warning(f"âš ï¸ ç„¡æ³•æ³¨å…¥æœƒè©±ç‹€æ…‹ä¿¡æ¯: {e}")

        # å¦‚æœæ˜¯batch processingæ¨¡å¼ï¼Œé¡å¤–ç®¡ç†ä¸Šä¸‹æ–‡
        if context.get("is_batch_processing", False):
            messages = self.manage_context_for_batch_processing(messages, context)
            managed_tokens = self.calculate_messages_tokens(messages)
            logger.info(f"ğŸ§  Batchæ¨¡å¼Tokenç®¡ç†å¾Œ: {managed_tokens}")
            # æ›´æ–°stateä¸­çš„messages
            state["messages"] = messages

        # æª¢æŸ¥æ˜¯å¦æ˜¯åˆå§‹æŸ¥è©¢
        is_initial_query = not any(
            isinstance(msg, (AIMessage, ToolMessage)) for msg in messages
        )

        if is_initial_query:
            logger.info(f"ğŸ¤– è™•ç†åˆå§‹ç”¨æˆ¶æŸ¥è©¢: {query}")

            # æ§‹å»ºç³»çµ±æç¤º
            system_prompt = self._get_system_prompt(rule_id, context)

            # æ§‹å»ºåŒ…å« context çš„ç”¨æˆ¶æŸ¥è©¢
            has_rule = rule_id is not None
            context_query = self._build_context_query(query, context, has_rule)

            # æ§‹å»ºæ¶ˆæ¯
            llm_messages = [SystemMessage(content=system_prompt)]
            llm_messages.append(HumanMessage(content=context_query))

        else:
            # é€™æ˜¯å·¥å…·åŸ·è¡Œå¾Œçš„é‡æ–°è©•ä¼°
            logger.info("ğŸ”„ å·¥å…·åŸ·è¡Œå¾Œé‡æ–°è©•ä¼°ï¼Œæ±ºå®šä¸‹ä¸€æ­¥å‹•ä½œ")

            # æª¢æŸ¥æœ€è¿‘çš„å·¥å…·åŸ·è¡Œçµæœ
            recent_tool_messages = [
                msg for msg in messages[-5:] if isinstance(msg, ToolMessage)
            ]

            # æª¢æŸ¥æ˜¯å¦å·²ç¶“åŸ·è¡Œäº†å¤ªå¤šå·¥å…·ï¼ˆé˜²æ­¢ç„¡é™å¾ªç’°ï¼‰
            tool_count = len([msg for msg in messages if isinstance(msg, ToolMessage)])
            if tool_count >= 12:
                logger.info(f"ğŸ›‘ å·²åŸ·è¡Œ {tool_count} å€‹å·¥å…·ï¼Œåœæ­¢ä¸¦ç”Ÿæˆå›ç­”")
                # ç›´æ¥ç”Ÿæˆå›ç­”ï¼Œä¸å†èª¿ç”¨å·¥å…·
                final_prompt = f"""åŸºæ–¼å·²åŸ·è¡Œçš„å·¥å…·çµæœï¼Œè«‹ç›´æ¥å›ç­”ç”¨æˆ¶çš„å•é¡Œï¼š

                    ç”¨æˆ¶è«‹æ±‚: {query}

                    å·²åŸ·è¡Œçš„å·¥å…·çµæœ:
                    {chr(10).join([f"- {msg.name}: {msg.content[:300]}..." for msg in recent_tool_messages])}

                    è«‹åŸºæ–¼é€™äº›ä¿¡æ¯æä¾›å®Œæ•´çš„å›ç­”ï¼Œä¸è¦å†èª¿ç”¨ä»»ä½•å·¥å…·ã€‚
                """

                llm_messages = [
                    SystemMessage(
                        content="ä½ æ˜¯ä¸€å€‹æ™ºèƒ½åŠ©æ‰‹ã€‚è«‹åŸºæ–¼æä¾›çš„ä¿¡æ¯ç›´æ¥å›ç­”ç”¨æˆ¶å•é¡Œï¼Œä¸è¦èª¿ç”¨ä»»ä½•å·¥å…·ã€‚"
                    ),
                    HumanMessage(content=final_prompt),
                ]
            elif recent_tool_messages:
                # æª¢æŸ¥æ˜¯å¦ç²å¾—äº†æœ‰æ•ˆçš„é é¢å…§å®¹
                page_content_found = False
                for msg in recent_tool_messages:
                    if (
                        msg.name == "browser_get_page_data_tool"
                        and len(msg.content) > 100
                    ):
                        page_content_found = True
                        break

                if page_content_found:
                    logger.info("âœ… å·²ç²å¾—æœ‰æ•ˆçš„é é¢å…§å®¹ï¼Œæº–å‚™ç”Ÿæˆå›ç­”")
                    # æœ‰äº†é é¢å…§å®¹ï¼Œæ‡‰è©²å¯ä»¥å›ç­”äº†
                    evaluation_prompt = f"""ä½ å·²ç¶“æˆåŠŸç²å–äº†é é¢å…§å®¹ã€‚è«‹åŸºæ–¼ä»¥ä¸‹ä¿¡æ¯ç›´æ¥å›ç­”ç”¨æˆ¶çš„å•é¡Œï¼š

                        ç”¨æˆ¶è«‹æ±‚: {query}

                        é é¢å…§å®¹:
                        {chr(10).join([f"- {msg.name}: {msg.content[:500]}..." for msg in recent_tool_messages if msg.name == "browser_get_page_data_tool"])}

                        è«‹æä¾›å®Œæ•´çš„å›ç­”ï¼Œä¸éœ€è¦å†èª¿ç”¨å…¶ä»–å·¥å…·ã€‚
                    """
                else:
                    # æ²’æœ‰ç²å¾—æœ‰æ•ˆå…§å®¹ï¼Œå¯èƒ½éœ€è¦é‡è©¦
                    evaluation_prompt = f"""åŸºæ–¼ä»¥ä¸‹å·¥å…·åŸ·è¡Œçµæœï¼Œè«‹åˆ†ææ˜¯å¦éœ€è¦èª¿ç”¨æ›´å¤šå·¥å…·ä¾†å®Œæˆç”¨æˆ¶çš„è«‹æ±‚ï¼š
                        ç”¨æˆ¶åŸå§‹è«‹æ±‚: {query}

                        æœ€è¿‘çš„å·¥å…·åŸ·è¡Œçµæœ:
                        {chr(10).join([f"- {msg.name}: {msg.content[:200]}..." for msg in recent_tool_messages])}

                        è«‹æ±ºå®šï¼š
                        1. å¦‚æœéœ€è¦æ›´å¤šå·¥å…·ä¾†å®Œæˆä»»å‹™ï¼Œè«‹èª¿ç”¨ç›¸æ‡‰çš„å·¥å…·
                        2. å¦‚æœå·²ç¶“æœ‰è¶³å¤ çš„ä¿¡æ¯ï¼Œè«‹ç›´æ¥å›ç­”ç”¨æˆ¶

                        æ³¨æ„ï¼šé¿å…é‡è¤‡èª¿ç”¨ç›¸åŒçš„å·¥å…·ï¼Œé™¤éæœ‰æ–°çš„åƒæ•¸æˆ–éœ€æ±‚ã€‚
                    """

                llm_messages = [
                    SystemMessage(content=self._get_system_prompt(rule_id, context)),
                    HumanMessage(content=evaluation_prompt),
                ]

                # æ·»åŠ å°è©±æ­·å²ï¼Œç¢ºä¿ tool_call_id å®Œæ•´æ€§
                # æ‰¾åˆ°æœ€å¾Œä¸€å€‹å®Œæ•´çš„ AI -> Tool å°è©±çµ„
                recent_messages = self._get_recent_complete_messages(
                    messages, max_messages=10
                )
                llm_messages.extend(recent_messages)
            else:
                # æ²’æœ‰å·¥å…·æ¶ˆæ¯ï¼Œç›´æ¥ä½¿ç”¨ç¾æœ‰æ¶ˆæ¯
                llm_messages = [
                    SystemMessage(content=self._get_system_prompt(rule_id, context))
                ]
                llm_messages.extend(messages)

        # èª¿ç”¨ LLM é€²è¡Œæ±ºç­–
        response = await self.current_llm_with_tools.ainvoke(llm_messages)

        # è¨˜éŒ„æ±ºç­–çµæœ
        if hasattr(response, "tool_calls") and response.tool_calls:
            tool_names = [call["name"] for call in response.tool_calls]
            logger.info(f"ğŸ”§ æ±ºå®šèª¿ç”¨å·¥å…·: {tool_names}")
        else:
            logger.info("ğŸ’¬ æ±ºå®šç›´æ¥å›æ‡‰ç”¨æˆ¶")

        return {"messages": [response]}

    def _get_recent_complete_messages(
        self, messages: List, max_messages: int = 10
    ) -> List:
        """
        ç²å–æœ€è¿‘çš„å®Œæ•´æ¶ˆæ¯çµ„ï¼Œç¢ºä¿ AI æ¶ˆæ¯å’Œå°æ‡‰çš„ ToolMessage éƒ½è¢«åŒ…å«

        Args:
            messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            max_messages: æœ€å¤§æ¶ˆæ¯æ•¸é‡

        Returns:
            å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
        """
        if len(messages) <= max_messages:
            return messages

        # å¾å¾Œå¾€å‰æ‰¾ï¼Œç¢ºä¿åŒ…å«å®Œæ•´çš„ AI -> Tool å°è©±çµ„
        result_messages = []
        i = len(messages) - 1

        while i >= 0 and len(result_messages) < max_messages:
            current_msg = messages[i]
            result_messages.insert(0, current_msg)

            # å¦‚æœæ˜¯ ToolMessageï¼Œç¢ºä¿å°æ‡‰çš„ AI æ¶ˆæ¯ä¹Ÿè¢«åŒ…å«
            if isinstance(current_msg, ToolMessage):
                # å‘å‰æŸ¥æ‰¾å°æ‡‰çš„ AI æ¶ˆæ¯
                j = i - 1
                while j >= 0:
                    prev_msg = messages[j]
                    if (
                        isinstance(prev_msg, AIMessage)
                        and hasattr(prev_msg, "tool_calls")
                        and prev_msg.tool_calls
                    ):
                        # æª¢æŸ¥æ˜¯å¦åŒ…å«å°æ‡‰çš„ tool_call_id
                        tool_call_ids = [
                            call.get("id", "") for call in prev_msg.tool_calls
                        ]
                        if current_msg.tool_call_id in tool_call_ids:
                            # ç¢ºä¿é€™å€‹ AI æ¶ˆæ¯ä¹Ÿè¢«åŒ…å«
                            if prev_msg not in result_messages:
                                result_messages.insert(0, prev_msg)
                            break
                    j -= 1

            i -= 1

        return result_messages

    def _get_system_prompt(
        self, rule_id: Optional[str], context: Dict[str, Any]
    ) -> str:
        """ç²å–ç³»çµ±æç¤º"""

        # ç²å–ç•¶å‰å°ç£æ™‚é–“
        from datetime import datetime
        import pytz

        taiwan_tz = pytz.timezone("Asia/Taipei")
        current_time = datetime.now(taiwan_tz).strftime("%Y-%m-%d %H:%M:%S (å°ç£æ™‚é–“)")
        if rule_id:
            # è¼‰å…¥è¦å‰‡æç¤º
            rule_data = self.find_rule_by_name(rule_id)
            if rule_data and rule_data.get("prompt"):
                logger.info(f"ğŸ“‹ ä½¿ç”¨è¦å‰‡æç¤º: {rule_data.get('name', rule_id)}")

                rule_prompt = rule_data["prompt"]

                # å¾ context ä¸­ç²å– file_path
                file_path = "æœªæä¾›"
                if context and isinstance(context, dict):
                    context_data = context.get("context_data", {})
                    if isinstance(context_data, dict):
                        file_path = context_data.get("file_path", "æœªæä¾›")

                # æ›¿æ›å ä½ç¬¦
                rule_prompt = rule_prompt.replace("{file_path}", str(file_path))
                rule_prompt = rule_prompt.replace("{current_time}", current_time)

                return rule_prompt

        # é è¨­æç¤º
        return f"""ä½ æ˜¯ä¸€å€‹æ™ºèƒ½æ•¸æ“šåˆ†æåŠ©æ‰‹ã€‚ç•¶å‰æ™‚é–“: {current_time}

ğŸ¯ **æ ¸å¿ƒä»»å‹™**ï¼šä¸»å‹•é€²è¡Œåˆ†æï¼Œè€Œä¸åªæ˜¯æä¾›å»ºè­°

ğŸ“Š **æ•¸æ“šåˆ†æå„ªå…ˆåŸå‰‡**ï¼š
ç•¶ç”¨æˆ¶æåˆ°çµ±è¨ˆã€åˆ†æã€è¨ˆç®—ã€éæ¿¾ç­‰éœ€æ±‚æ™‚ï¼Œè«‹ç«‹å³åŸ·è¡Œå¯¦éš›çš„æ•¸æ“šåˆ†æï¼š

1. **éæ¿¾æ•¸æ“š**ï¼šä½¿ç”¨ filter_data_tool éæ¿¾å‡ºç¬¦åˆæ¢ä»¶çš„æ•¸æ“š
   - ä¾‹å¦‚ï¼šéæ¿¾ç‰¹å®šéƒ¨é–€ã€æ—¥æœŸç¯„åœã€é‡‘é¡ç¯„åœç­‰
   - è¨­ç½® save_filtered_data=True ä¿å­˜éæ¿¾çµæœ

2. **åˆ†çµ„åˆ†æ**ï¼šä½¿ç”¨ group_by_analysis_tool é€²è¡Œçµ±è¨ˆè¨ˆç®—
   - æ”¯æŒæ“ä½œï¼šsum(ç¸½å’Œ)ã€mean(å¹³å‡)ã€count(è¨ˆæ•¸)ã€max(æœ€å¤§)ã€min(æœ€å°)
   - ä¾‹å¦‚ï¼šæŒ‰éƒ¨é–€åˆ†çµ„è¨ˆç®—æ”¯å‡ºç¸½é¡

3. **çµ„åˆåˆ†æ**ï¼šä½¿ç”¨ filter_and_analyze_tool ä¸€æ­¥å®Œæˆéæ¿¾å’Œåˆ†æ

ğŸš€ **åŸ·è¡Œç­–ç•¥**ï¼š
- çœ‹åˆ°"çµ±è¨ˆXXéƒ¨é–€æ”¯å‡º"â†’ç«‹å³éæ¿¾è©²éƒ¨é–€æ•¸æ“šä¸¦è¨ˆç®—ç¸½é¡
- çœ‹åˆ°"åˆ†æXXè¶¨å‹¢"â†’éæ¿¾ç›¸é—œæ•¸æ“šä¸¦é€²è¡Œåˆ†çµ„åˆ†æ
- çœ‹åˆ°"è¨ˆç®—å¹³å‡å€¼"â†’ä½¿ç”¨group_by_analysis_toolåŸ·è¡Œmeanæ“ä½œ
- ä¸è¦åªæä¾›å»ºè­°ï¼Œè¦ç›´æ¥åŸ·è¡Œåˆ†æä¸¦çµ¦å‡ºå…·é«”çµæœ

è«‹æ ¹æ“šç”¨æˆ¶éœ€æ±‚æ™ºèƒ½åœ°é¸æ“‡å’Œä½¿ç”¨å·¥å…·ä¾†å®Œæˆä»»å‹™ã€‚"""

    def _build_context_query(
        self, query: str, context: Dict[str, Any], has_rule: bool = False
    ) -> str:
        """æ§‹å»ºåŒ…å« context ä¿¡æ¯çš„ç”¨æˆ¶æŸ¥è©¢"""

        # æå–é—œéµä¿¡æ¯
        context_data = context.get("context_data", {})
        file_path = context_data.get("file_path", "æœªçŸ¥æ–‡ä»¶")
        data_info = context_data.get("data_info", {})
        file_summary = context_data.get("file_summary", {})
        page_data = context_data.get("page", {})
        mails = context_data.get("mails", [])

        # æª¢æŸ¥æ˜¯å¦ç‚º Gmail æ•¸æ“š
        email_address = context_data.get("email_address", "")
        gmail_metadata = context_data.get("gmail_metadata", {})
        original_query = context_data.get("original_query", "")

        # æ§‹å»ºç°¡æ½”çš„æ•¸æ“šæ‘˜è¦
        data_summary = ""

        # Gmail æ•¸æ“šæ‘˜è¦ï¼ˆå„ªå…ˆä½¿ç”¨ file_summaryï¼‰
        if file_summary and file_summary.get("file_type") == "gmail_csv":
            total_emails = file_summary.get("total_emails", 0)
            unread_emails = file_summary.get("unread_emails", 0)
            top_senders = file_summary.get("top_senders", [])

            data_summary = f"""
                ğŸ“§ Gmail éƒµä»¶æ•¸æ“šå·²è¼‰å…¥ä¸¦æº–å‚™åˆ†æ:
                - éƒµä»¶å¸³æˆ¶: {email_address}
                - éƒµä»¶æ•¸é‡: {total_emails} å°
                - æœªè®€éƒµä»¶: {unread_emails} å°
                - æ•¸æ“šæ–‡ä»¶: {file_path}
                - ä¸»è¦ç™¼ä»¶äºº: {', '.join([f"{sender}({count}å°)" for sender, count in top_senders[:3]])}
                - åŸå§‹æŸ¥è©¢: {original_query}
                - æ–‡ä»¶æ‘˜è¦: {file_summary.get('summary', '')}
            """
        # Gmail æ•¸æ“šæ‘˜è¦ï¼ˆå›é€€åˆ° gmail_metadataï¼‰
        elif email_address and gmail_metadata:
            total_emails = gmail_metadata.get("total_emails", 0)
            data_summary = f"""
                ğŸ“§ Gmail éƒµä»¶æ•¸æ“šå·²è¼‰å…¥ä¸¦æº–å‚™åˆ†æ:
                - éƒµä»¶å¸³æˆ¶: {email_address}
                - éƒµä»¶æ•¸é‡: {total_emails} å°
                - æ•¸æ“šæ–‡ä»¶: {file_path}
                - åŸå§‹æŸ¥è©¢: {original_query}
                - æˆåŠŸæ‰¹æ¬¡: {gmail_metadata.get('successful_batches', 0)}
                - å¤±æ•—æ‰¹æ¬¡: {gmail_metadata.get('failed_batches', 0)}
            """
        # ä¸€èˆ¬æ•¸æ“šæ–‡ä»¶æ‘˜è¦ï¼ˆå„ªå…ˆä½¿ç”¨ file_summaryï¼‰
        elif file_summary:
            total_rows = file_summary.get(
                "total_emails", file_summary.get("total_rows", 0)
            )
            columns = file_summary.get("columns", [])
            summary_text = file_summary.get("summary", "")

            data_summary = f"""
                ğŸ“Š æ•¸æ“šæ–‡ä»¶å·²è¼‰å…¥ä¸¦æº–å‚™åˆ†æ:
                - æ–‡ä»¶è·¯å¾‘: {file_path}
                - æ•¸æ“šæ‘˜è¦: {summary_text}
                - æ•¸æ“šé‡: {total_rows} è¡Œ
                - æ¬„ä½: {', '.join(columns[:10])}{'...' if len(columns) > 10 else ''}
            """
        # ä¸€èˆ¬æ•¸æ“šæ–‡ä»¶æ‘˜è¦ï¼ˆå›é€€åˆ° data_infoï¼‰
        elif data_info:
            total_rows = data_info.get("total_rows", 0)
            columns = data_info.get("columns", [])
            numeric_columns = data_info.get("numeric_columns", [])
            categorical_columns = data_info.get("categorical_columns", [])

            data_summary = f"""
                ğŸ“Š æ•¸æ“šæ–‡ä»¶å·²è¼‰å…¥ä¸¦æº–å‚™åˆ†æ:
                - æ–‡ä»¶è·¯å¾‘: {file_path}
                - æ•¸æ“šè¡Œæ•¸: {total_rows} è¡Œ
                - ç¸½æ¬„ä½æ•¸: {len(columns)} å€‹
                - æ•¸å€¼æ¬„ä½: {', '.join(numeric_columns[:10])}{'...' if len(numeric_columns) > 10 else ''}
                - åˆ†é¡æ¬„ä½: {', '.join(categorical_columns[:10])}{'...' if len(categorical_columns) > 10 else ''}
            """

        if has_rule:
            instruction = f"""
                {data_summary}
                æ­¤ç‚ºæˆ‘çš„é é¢è³‡æ–™ {context_data}
                è«‹æ ¹æ“šæˆ‘çš„éœ€æ±‚ï¼Œä»¥åŠä½ çš„è¦å‰‡ï¼ˆSystem Promptï¼‰ï¼Œå¹«åŠ©æˆ‘è§£æ±ºå•é¡Œ
                æˆ‘çš„éœ€æ±‚: "{query}"ï¼Œå¦‚æœæ˜¯ç©ºå­—ä¸²ï¼Œè«‹æ ¹æ“šä½ çš„è¦å‰‡ï¼ˆSystem Promptï¼‰ï¼Œå¹«åŠ©æˆ‘è§£æ±ºå•é¡Œ
            """

        elif mails:
            instruction = f"""
                éƒµä»¶å·²æº–å‚™å®Œæˆï¼Œè«‹æ ¹æ“šä½ çš„å°ˆæ¥­è¦å‰‡å’Œæ­¥é©Ÿç›´æ¥é–‹å§‹é€²è¡Œå®Œæ•´çš„åˆ†æã€‚
                è«‹ä½ è©³ç´°åˆ†æéƒµä»¶çš„å…§å®¹ã€‚

                éƒµä»¶: {mails}

                ç”¨æˆ¶éœ€æ±‚: "{query}"
            """

        else:
            instruction = f"""{data_summary}

ğŸ¯ **ç«‹å³åŸ·è¡Œæ•¸æ“šåˆ†æ**ï¼š
æ ¹æ“šç”¨æˆ¶éœ€æ±‚ï¼Œè«‹ç›´æ¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·é€²è¡Œå¯¦éš›åˆ†æï¼š

1. å¦‚æœéœ€è¦éæ¿¾æ•¸æ“šï¼šä½¿ç”¨ filter_data_tool
2. å¦‚æœéœ€è¦çµ±è¨ˆè¨ˆç®—ï¼šä½¿ç”¨ group_by_analysis_tool
3. å¦‚æœéœ€è¦çµ„åˆæ“ä½œï¼šä½¿ç”¨ filter_and_analyze_tool

âš ï¸ **é‡è¦**ï¼šä¸è¦åªæä¾›å»ºè­°æˆ–èªªæ˜ï¼Œè«‹ç«‹å³åŸ·è¡Œå¯¦éš›çš„æ•¸æ“šåˆ†æä¸¦æä¾›å…·é«”çµæœã€‚

ç”¨æˆ¶éœ€æ±‚: "{query}"

è«‹ç«‹å³é–‹å§‹åˆ†æä¸¦åŸ·è¡Œç›¸æ‡‰çš„å·¥å…·ã€‚"""

        return instruction

    def find_rule_by_name(self, rule_name: str) -> Optional[Dict[str, Any]]:
        """æ ¹æ“š rule name æŸ¥æ‰¾è¦å‰‡ - ç°¡å–®ç›´æ¥çš„æ–¹æ³•"""
        try:
            from pathlib import Path
            import json

            rules_dir = Path(self.rules_dir)

            # éæ­·æ‰€æœ‰ JSON æ–‡ä»¶
            for rule_file in rules_dir.glob("*.json"):
                try:
                    with open(rule_file, "r", encoding="utf-8") as f:
                        rule_data = json.load(f)
                        # ç›´æ¥æ¯”å° name å­—æ®µ
                        if rule_data.get("name") == rule_name:
                            return rule_data
                except Exception as e:
                    logger.warning(f"âš ï¸ è®€å–è¦å‰‡æ–‡ä»¶å¤±æ•— {rule_file.name}: {e}")
                    continue

            return None
        except Exception as e:
            logger.error(f"âŒ æŸ¥æ‰¾è¦å‰‡å¤±æ•— {rule_name}: {e}")
            return None

    async def response_generator_node(
        self, state: SupervisorAgentState
    ) -> Dict[str, Any]:
        """å›ç­”ç”Ÿæˆç¯€é»"""
        messages = state.get("messages", [])
        query = state.get("query", "")
        rule_id = state.get("rule_id")

        logger.info("ğŸ¤– ç”Ÿæˆæœ€çµ‚å›ç­”...")

        # æª¢æŸ¥æ˜¯å¦æœ‰å·¥å…·èª¿ç”¨çµæœ
        has_tool_results = any(isinstance(msg, ToolMessage) for msg in messages)

        if has_tool_results:
            # æœ‰å·¥å…·èª¿ç”¨çµæœï¼Œç”ŸæˆåŸºæ–¼çµæœçš„å›ç­”
            # é¦–å…ˆå˜—è©¦ç²å– rule ä¸­çš„ prompt ä½œç‚ºç³»çµ±æç¤º
            rule_prompt = None
            if rule_id:
                rule_data = self.find_rule_by_name(rule_id)
                if rule_data and rule_data.get("prompt"):
                    rule_prompt = rule_data["prompt"]
                    logger.info(f"ğŸ“‹ ä½¿ç”¨è¦å‰‡ {rule_id} çš„ prompt ä½œç‚ºå›ç­”ç”ŸæˆæŒ‡å°")

            if rule_prompt:
                # ä½¿ç”¨ rule ä¸­çš„ promptï¼Œä¸¦æ·»åŠ åŸºæœ¬çš„å›ç­”ç”ŸæˆæŒ‡å°
                system_prompt = f"""{rule_prompt}

=== å›ç­”ç”ŸæˆæŒ‡å° ===
è«‹æ ¹æ“šä¸Šè¿°è¦å‰‡å’Œå·¥å…·åŸ·è¡Œçµæœç‚ºç”¨æˆ¶ç”Ÿæˆå›ç­”ã€‚

åŸºæœ¬è¦æ±‚ï¼š
1. å›ç­”è¦å…·é«”ä¸”æœ‰ç”¨
2. å¦‚æœæœ‰æ•¸æ“šï¼Œè«‹æä¾›å…·é«”æ•¸å­—
3. å¦‚æœæœ‰éŒ¯èª¤ï¼Œè«‹èªªæ˜åŸå› ä¸¦æä¾›è§£æ±ºå»ºè­°
4. ä¿æŒå°ˆæ¥­ä¸”å‹å¥½çš„èªèª¿
5. åš´æ ¼éµå¾ªä¸Šè¿°è¦å‰‡ä¸­çš„ output_format è¦æ±‚

è«‹æ ¹æ“šå·¥å…·åŸ·è¡Œçµæœå’Œä¸Šè¿°è¦å‰‡è¦æ±‚ç”Ÿæˆæœ€çµ‚å›ç­”ã€‚"""
            else:
                # æ²’æœ‰ rule promptï¼Œä½¿ç”¨é è¨­çš„ç³»çµ±æç¤º
                system_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„åŠ©æ‰‹ï¼Œè«‹æ ¹æ“šå·¥å…·åŸ·è¡Œçµæœç‚ºç”¨æˆ¶ç”Ÿæˆç°¡æ½”æ˜ç­çš„å›ç­”ã€‚

è¦æ±‚ï¼š
1. å›ç­”è¦å…·é«”ä¸”æœ‰ç”¨
2. å¦‚æœæœ‰æ•¸æ“šï¼Œè«‹æä¾›å…·é«”æ•¸å­—
3. å¦‚æœæœ‰éŒ¯èª¤ï¼Œè«‹èªªæ˜åŸå› ä¸¦æä¾›è§£æ±ºå»ºè­°
4. ä¿æŒå°ˆæ¥­ä¸”å‹å¥½çš„èªèª¿
5. ç”¨ç¹é«”ä¸­æ–‡å›ç­”

ğŸ“Š **ç‰¹åˆ¥æ³¨æ„ - æ•¸æ“šåˆ†æå›ç­”æ ¼å¼**ï¼š
ç•¶å›ç­”æ¶‰åŠæ•¸æ“šåˆ†æçµæœæ™‚ï¼Œè«‹æŒ‰ä»¥ä¸‹æ ¼å¼æä¾›è±å¯Œçš„å…§å®¹ï¼š

## ğŸ“ˆ åˆ†æçµæœ

### ğŸ¯ æ ¸å¿ƒç™¼ç¾
[ç›´æ¥å›ç­”ç”¨æˆ¶å•é¡Œçš„ä¸»è¦æ•¸å­—å’Œçµè«–]

### ğŸ“Š è©³ç´°æ•¸æ“š
```
| é …ç›® | æ•¸å€¼ | ä½”æ¯” |
|------|------|------|
| ... | ... | ... |
```

### ğŸ’¡ é‡é»æ•´ç† ç¯„ä¾‹
- é‡é»1ï¼š[å…·é«”ç™¼ç¾]
- é‡é»2ï¼š[ç•°å¸¸æˆ–ç‰¹æ®Šæƒ…æ³]
- é‡é»3ï¼š[å…¶ä»–å»¶ä¼¸è³‡è¨Šï¼Œæˆ–æ˜¯ç”¨æˆ¶å¯èƒ½æƒ³è¦çŸ¥é“çš„å…§å®¹]

### ğŸ“‹ è£œå……èªªæ˜ ç¯„ä¾‹
- æ•¸æ“šä¾†æºï¼š[èªªæ˜æ•¸æ“šç¯„åœ]
- çµ±è¨ˆæ–¹æ³•ï¼š[èªªæ˜ä½¿ç”¨çš„åˆ†ææ–¹æ³•]
- ç›¸é—œå»ºè­°ï¼š[åŸºæ–¼æ•¸æ“šçš„å»ºè­°ï¼Œæˆ–æ˜¯ç”¨æˆ¶å¯èƒ½æƒ³è¦çŸ¥é“çš„å…§å®¹]

ä¸è¦åªçµ¦ä¸€å€‹å–®è–„çš„æ•¸å­—æˆ–æ˜¯æ–‡å­—å›è¦†ï¼Œè¦æä¾›å®Œæ•´çš„åˆ†æå ±å‘Šã€‚"""

            response_messages = [SystemMessage(content=system_prompt)]
            response_messages.extend(messages)

            final_instruction = f"""ç”¨æˆ¶å•é¡Œï¼š{query}

è«‹æ ¹æ“šä¸Šè¿°å·¥å…·åŸ·è¡Œçµæœç”Ÿæˆæœ€çµ‚å›ç­”ã€‚

âš ï¸ å¦‚æœæ¶‰åŠæ•¸æ“šåˆ†æï¼Œè«‹å‹™å¿…ä½¿ç”¨ä¸Šè¿°æŒ‡å®šçš„æ ¼å¼ï¼š
- åŒ…å«æ ¸å¿ƒç™¼ç¾ã€è©³ç´°æ•¸æ“šè¡¨æ ¼ã€é‡é»æ•´ç†ã€è£œå……èªªæ˜
- ä¸è¦åªçµ¦ä¸€å€‹ç°¡å–®çš„æ•¸å­—ç­”æ¡ˆ"""

            response_messages.append(HumanMessage(content=final_instruction))
            final_response = await self.llm.ainvoke(response_messages)

            response_content = (
                final_response.content
                if hasattr(final_response, "content")
                else "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è™•ç†é€™å€‹è«‹æ±‚ã€‚"
            )
        else:
            # æ²’æœ‰å·¥å…·èª¿ç”¨ï¼Œä½¿ç”¨ç›´æ¥å›æ‡‰
            last_message = messages[-1] if messages else None
            if last_message and hasattr(last_message, "content"):
                response_content = last_message.content
            else:
                response_content = "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è™•ç†é€™å€‹è«‹æ±‚ã€‚"

        logger.info(f"âœ… æœ€çµ‚å›ç­”ç”Ÿæˆå®Œæˆ: {response_content[:100]}...")

        return {"messages": [AIMessage(content=response_content)]}

    async def run(
        self,
        query: str,
        rule_id: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None,
        available_tools: List = None,
    ) -> Dict[str, Any]:
        """åŸ·è¡ŒæŸ¥è©¢ä¸¦è¿”å›å›æ‡‰"""

        logger.info(f"ğŸš€ é–‹å§‹è™•ç†æŸ¥è©¢: {query}")
        logger.info(f"ğŸ” è©³ç´°åƒæ•¸:")
        logger.info(f"  - query: {query}")
        logger.info(f"  - rule_id: {rule_id}")

        # é™åˆ¶ context æ—¥èªŒè¼¸å‡ºé•·åº¦
        context_str = str(context)
        if len(context_str) > 300:
            context_str = context_str[:300] + "..."
        logger.info(f"  - context: {context_str}")

        # æ ¹æ“š rule_id è¼‰å…¥è¦å‰‡
        rule_data = None
        if rule_id:
            rule_data = self.find_rule_by_name(rule_id)
            if not rule_data:
                logger.info(f"âš ï¸ æœªæ‰¾åˆ°è¦å‰‡: {rule_id}")

        # æ ¹æ“šè¦å‰‡è¨­ç½®å·¥å…·
        if rule_data:
            tool_names = rule_data.get("tools", [])
            logger.info(f"ğŸ”§ è¦å‰‡ä¸­çš„å·¥å…·: {tool_names}")
            self.setup_tools_for_query(tool_names, available_tools)
            logger.info(
                f"ğŸ“‹ ä½¿ç”¨è¦å‰‡: {rule_data.get('name', rule_id)}ï¼Œè¦å‰‡å·¥å…·: {tool_names}"
            )
        else:
            # æ²’æœ‰è¦å‰‡ï¼Œä½¿ç”¨å¤–éƒ¨æä¾›çš„å·¥å…·æˆ–é»˜èªå·¥å…·
            self.setup_tools_for_query([], available_tools)
            if available_tools:
                logger.info("ğŸ“ ä½¿ç”¨å¤–éƒ¨æä¾›çš„ Local File Use Tools")
            else:
                logger.info("ğŸ’¬ ä½¿ç”¨é è¨­æ¨¡å¼ï¼ˆç€è¦½å™¨å·¥å…·ï¼‰")

        # ä½¿ç”¨åŸå§‹æŸ¥è©¢ä½œç‚ºè™•ç†å…§å®¹
        parsed_query = query

        initial_state = {
            "messages": [],
            "query": parsed_query,
            "rule_id": rule_id,
            "context": context or {},
        }

        config = {
            "configurable": {"thread_id": str(uuid.uuid4())},
            "recursion_limit": 50,  # å¢åŠ éæ­¸é™åˆ¶åˆ° 50
            # "callbacks": [self.tracer],  # è¨»è§£æ‰ LangSmith tracer
        }

        # åŸ·è¡Œ graph
        start_time = time.time()
        # TODO: é€™æ˜¯ç‚ºä»€éº¼ æµå¼å›è¦†æ¥ä¸åˆ°ToolMessage
        result = await self.current_graph.ainvoke(initial_state, config=config)
        execution_time = time.time() - start_time

        logger.info(f"â±ï¸ æŸ¥è©¢åŸ·è¡Œå®Œæˆï¼Œè€—æ™‚ {execution_time:.2f}ç§’")

        # æå–æœ€çµ‚å›æ‡‰
        final_message = result["messages"][-1]

        if isinstance(final_message, AIMessage):
            response_content = final_message.content
        else:
            response_content = "æŠ±æ­‰ï¼Œç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚"

        # æå–ä½¿ç”¨çš„å·¥å…·
        tools_used = []
        for msg in result["messages"]:
            if isinstance(msg, ToolMessage):
                tools_used.append(msg.name)

        return {
            "response": response_content,
            "rule_id": rule_id,
            "tools_used": tools_used,
            "execution_time": execution_time,
            "context": context or {},
        }

    # å…·é«”çš„æ¥­å‹™æ–¹æ³•
    async def gmail_summary(
        self, days: int = 7, keywords: List[str] = None
    ) -> Dict[str, Any]:
        """Gmail éƒµä»¶æ‘˜è¦"""
        query = f"å¹«æˆ‘ç¸½çµæœ€è¿‘ {days} å¤©çš„æœªè®€éƒµä»¶"
        if keywords:
            query += f"ï¼Œç‰¹åˆ¥é—œæ³¨åŒ…å« {', '.join(keywords)} çš„éƒµä»¶"

        return await self.run(query, context={"days": days, "keywords": keywords})

    async def mark_important_emails(self, days: int = 7) -> Dict[str, Any]:
        """æ¨™è¨˜é‡è¦éƒµä»¶"""
        query = f"å¹«æˆ‘æª¢æŸ¥æœ€è¿‘ {days} å¤©çš„éƒµä»¶ï¼Œä¸¦æ¨™è¨˜é‡è¦çš„éƒµä»¶"
        return await self.run(query, context={"days": days})

    async def download_invoices(self, sender: str = "google colab") -> Dict[str, Any]:
        """ä¸‹è¼‰ç™¼ç¥¨"""
        query = f"å¹«æˆ‘ä¸‹è¼‰æ‰€æœ‰ä¾†è‡ª {sender} çš„ç™¼ç¥¨"
        return await self.run(query, context={"sender": sender})

    async def browser_automation(self, action: str, **kwargs) -> Dict[str, Any]:
        """ç€è¦½å™¨è‡ªå‹•åŒ–"""
        query = f"åŸ·è¡Œç€è¦½å™¨æ“ä½œ: {action}"
        return await self.run(query, context={"action": action, **kwargs})

    async def taaze_test(self, question: str = "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ") -> Dict[str, Any]:
        """Taaze.ai æ¸¬è©¦"""
        query = f"åœ¨ Taaze.ai ä¸Šæ¸¬è©¦å•ç­”åŠŸèƒ½ï¼Œå•é¡Œ: {question}"
        return await self.run(query, context={"question": question})

    async def get_status(self) -> Dict[str, Any]:
        """ç²å– Agent ç‹€æ…‹"""
        return {
            "status": "running",
            "tools_count": len(self.tools),
            "uptime": time.time(),
        }
