"""
Agent API è·¯ç”±

è™•ç†èˆ‡ Agent ç›¸é—œçš„è«‹æ±‚ï¼Œåªæä¾›æµå¼æ¥å£ã€‚
"""

import json
import numpy as np
from typing import AsyncGenerator, Dict, Any, Optional, List
from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

from supervisor_agent.core.supervisor_agent import SupervisorAgent

# æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘ä»¥å°å…¥å·¥å…·
import os
import sys
from pathlib import Path
current_dir = Path(__file__).parent
src_dir = current_dir.parent.parent / "src"
sys.path.insert(0, str(src_dir))

# å°å…¥ LangChain å…¼å®¹çš„æœ¬åœ°æ–‡ä»¶å·¥å…·
from supervisor_agent.tools.langchain_local_file_tools import get_langchain_local_file_tools
from supervisor_agent.utils.logger import get_logger

logger = get_logger(__name__)


def convert_numpy_types(obj):
    """
    éæ­¸è½‰æ›numpyé¡å‹ç‚ºPythonåŸç”Ÿé¡å‹ï¼Œè§£æ±ºJSONåºåˆ—åŒ–å•é¡Œ
    """
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_numpy_types(item) for item in obj)
    else:
        return obj


# å·¥å…·è½‰æ›å‡½æ•¸å·²ç§»é™¤ï¼Œç›´æ¥ä½¿ç”¨ LangChain å·¥å…·

# ç§»é™¤ä¸éœ€è¦çš„å‡½æ•¸ï¼Œç°¡åŒ–é‚è¼¯

def _determine_request_type(context_data: dict, page_data: dict) -> str:
    """
    åˆ¤æ–·è«‹æ±‚é¡å‹

    Args:
        context_data: ä¸Šä¸‹æ–‡æ•¸æ“š (local file)
        page_data: é é¢æ•¸æ“š (web)

    Returns:
        è«‹æ±‚é¡å‹: 'local_file', 'web'
    """
    if page_data:
        return 'web'
    else:
        return 'local_file'

# ç§»é™¤ session summary ç›¸é—œå‡½æ•¸

router = APIRouter()

# Session-based Agent ç®¡ç†
class AgentManager:
    """Agentç®¡ç†å™¨ï¼Œç‚ºæ¯å€‹sessionç¶­è­·ç¨ç«‹çš„agentå¯¦ä¾‹"""

    def __init__(self):
        self.agents: Dict[str, SupervisorAgent] = {}
        # å¾ backend/api/routers/agent.py åˆ° data/rules çš„æ­£ç¢ºè·¯å¾‘
        self.rules_dir = Path(__file__).parent.parent.parent.parent / "data" / "rules"
        logger.info(f"ğŸ“ AgentManager rules_dir: {self.rules_dir}")
        logger.info(f"ğŸ“ rules_dir æ˜¯å¦å­˜åœ¨: {self.rules_dir.exists()}")
        if self.rules_dir.exists():
            rule_files = list(self.rules_dir.glob("*.json"))
            logger.info(f"ğŸ“ æ‰¾åˆ°çš„ rule æ–‡ä»¶: {[f.name for f in rule_files]}")

    def get_agent(self, session_id: str, stream_callback=None) -> SupervisorAgent:
        """ç²å–æŒ‡å®šsessionçš„Agentå¯¦ä¾‹"""
        if session_id not in self.agents:
            logger.info(f"ğŸ†• ç‚ºsession {session_id} å‰µå»ºæ–°çš„Agentå¯¦ä¾‹")
            self.agents[session_id] = SupervisorAgent(str(self.rules_dir), stream_callback)
        else:
            # æ›´æ–°ç¾æœ‰agentçš„stream_callback
            self.agents[session_id].stream_callback = stream_callback
        return self.agents[session_id]

    def cleanup_agent(self, session_id: str):
        """æ¸…ç†æŒ‡å®šsessionçš„Agentå¯¦ä¾‹"""
        if session_id in self.agents:
            logger.info(f"ğŸ—‘ï¸ æ¸…ç†session {session_id} çš„Agentå¯¦ä¾‹")
            del self.agents[session_id]

    def get_active_sessions(self) -> List[str]:
        """ç²å–æ´»èºçš„sessionåˆ—è¡¨"""
        return list(self.agents.keys())

# å…¨åŸŸAgentç®¡ç†å™¨å¯¦ä¾‹
_agent_manager = AgentManager()

def get_agent(session_id: str = "default", stream_callback=None) -> SupervisorAgent:
    """ç²å–æŒ‡å®šsessionçš„Agentå¯¦ä¾‹"""
    return _agent_manager.get_agent(session_id, stream_callback)

def set_agent(agent: SupervisorAgent, session_id: str = "default"):
    """è¨­ç½®æŒ‡å®šsessionçš„Agentå¯¦ä¾‹"""
    _agent_manager.agents[session_id] = agent
    logger.info(f"âœ… Session {session_id} çš„Agentå¯¦ä¾‹å·²è¨­ç½®")


class StreamRequest(BaseModel):
    """æµå¼è«‹æ±‚æ¨¡å‹"""
    message: str = Field(..., description="ç”¨æˆ¶æ¶ˆæ¯")
    user_id: str = Field(default="default_user", description="ç”¨æˆ¶ID")
    session_id: str = Field(default="default_session", description="æœƒè©±ID")
    context_data: Optional[Dict[str, Any]] = Field(default=None, description="ä¸Šä¸‹æ–‡è³‡æ–™ï¼ˆé é¢æˆ–æ–‡ä»¶ï¼‰")
    page_data: Optional[Dict[str, Any]] = Field(default=None, description="ç•¶å‰é é¢è³‡æ–™ï¼ˆå‘å¾Œå…¼å®¹ï¼‰")


async def generate_stream_response(message: str, agent: SupervisorAgent, session_id: str = "default_session", context_data: dict = None, page_data: dict = None, request_type: str = 'default') -> AsyncGenerator[str, None]:
    """ç”Ÿæˆæµå¼éŸ¿æ‡‰"""

    # ç”¨æ–¼å­˜å„²streamäº‹ä»¶çš„åˆ—è¡¨
    stream_events = []

    # å®šç¾©streamå›èª¿å‡½æ•¸
    async def stream_callback(event_data):
        """æ”¶é›†å·¥å…·åŸ·è¡Œçµæœ"""
        stream_events.append(event_data)

    try:
        logger.info(f"ğŸš€ é–‹å§‹ç”Ÿæˆæµå¼éŸ¿æ‡‰")
        logger.info(f"  - message: {message}")
        logger.info(f"  - session_id: {session_id}")
        logger.info(f"  - context_data: {context_data}")
        logger.info(f"  - page_data: {page_data}")
        logger.info(f"  - request_type: {request_type}")

        # ğŸ¯ æ ¹æ“šè«‹æ±‚é¡å‹é¸æ“‡å·¥å…·é›†å’Œè™•ç†æ–¹å¼
        available_tools = []
        file_summary = None
        final_context = None

        if request_type == 'local_file':
            logger.info("ğŸ“ LOCAL FILE æ¨¡å¼ - ç›´æ¥è™•ç†æ–‡ä»¶")
            available_tools = get_langchain_local_file_tools()

            # ğŸ”„ **ç›´æ¥è™•ç†æ–‡ä»¶ï¼Œç²å– data_info**
            if context_data and context_data.get('file_path'):
                file_path = context_data.get('file_path')
                logger.info(f"ğŸ“„ è™•ç†æ–‡ä»¶: {file_path}")

                # ç›´æ¥èª¿ç”¨åº•å±¤çš„æ•¸æ“šåˆ†æå‡½æ•¸ç²å–æ•¸æ“šä¿¡æ¯
                from src.tools.data_analysis_tools import data_analysis_tools

                try:
                    data_info_result = await data_analysis_tools.get_data_info(file_path, session_id)
                    logger.info(f"ï¿½ get_data_info_tool åŸ·è¡Œçµæœ: {str(data_info_result)[:500]}...")

                    # æ§‹å»º final_contextï¼ŒåªåŒ…å« data_info
                    final_context = {
                        'file_path': file_path,
                        'data_info': data_info_result
                    }

                    # è©³ç´°è¨˜éŒ„å‚³çµ¦ agent çš„å…§å®¹
                    logger.info("ï¿½ å‚³çµ¦ Agent çš„ final_context å…§å®¹:")
                    logger.info(f"  - file_path: {final_context['file_path']}")
                    logger.info(f"  - data_info é¡å‹: {type(final_context['data_info'])}")

                    if isinstance(data_info_result, dict):
                        # è¨˜éŒ„ data_info çš„é—œéµä¿¡æ¯
                        sample_data = data_info_result.get('sample_data', [])
                        total_rows = data_info_result.get('total_rows', 0)
                        columns = data_info_result.get('columns', [])

                        logger.info(f"  - sample_data æ•¸é‡: {len(sample_data)}")
                        logger.info(f"  - total_rows: {total_rows}")
                        logger.info(f"  - columns: {columns}")
                        logger.info(f"  - sample_data å…§å®¹: {sample_data}")

                        # ç¢ºä¿æœ‰ sample_data
                        if sample_data:
                            logger.info("âœ… æˆåŠŸç²å– sample_dataï¼Œå°‡å‚³çµ¦ Agent")
                        else:
                            logger.warning("âš ï¸ sample_data ç‚ºç©º")

                except Exception as e:
                    logger.error(f"âŒ è™•ç†æ–‡ä»¶å¤±æ•—: {e}")
                    final_context = {'error': f'æ–‡ä»¶è™•ç†å¤±æ•—: {str(e)}'}
            else:
                logger.error("âŒ æ²’æœ‰æä¾› file_path")
                final_context = {'error': 'æ²’æœ‰æä¾›æ–‡ä»¶è·¯å¾‘'}

        elif request_type == 'web':
            logger.info("ğŸŒ WEB æ¨¡å¼ - ä½¿ç”¨ Web Tools")
            # TODO: æ·»åŠ  Web Tools
            available_tools = []  # æš«æ™‚ç‚ºç©ºï¼Œç­‰å¾…å¯¦ç¾ Web Tools
            final_context = page_data
            logger.info(f"  - ä½¿ç”¨ä¸Šä¸‹æ–‡: {json.dumps(final_context, ensure_ascii=False, indent=2)}")

        else:
            logger.info("ğŸ”§ DEFAULT æ¨¡å¼ - ä½¿ç”¨é»˜èªå·¥å…·é›†")
            available_tools = get_langchain_local_file_tools()
            final_context = context_data or page_data
            if final_context:
                logger.info(f"  - ä½¿ç”¨ä¸Šä¸‹æ–‡: {json.dumps(final_context, ensure_ascii=False, indent=2)}")
            else:
                logger.info(f"  - ç„¡ä¸Šä¸‹æ–‡æ•¸æ“š")

        logger.info(f"ğŸ”§ é¸æ“‡çš„å·¥å…·æ•¸é‡: {len(available_tools)}")

        # ç™¼é€é–‹å§‹äº‹ä»¶
        if request_type == 'local_file':
            start_event = {'type': 'start', 'message': 'ğŸ“ Local File æ¨¡å¼ï¼šæ–‡ä»¶é è™•ç†å·²å®Œæˆï¼Œé–‹å§‹åˆ†æ...'}
        elif request_type == 'web':
            start_event = {'type': 'start', 'message': 'ğŸŒ Web æ¨¡å¼ï¼šé–‹å§‹è™•ç†ç¶²é å…§å®¹...'}
        else:
            start_event = {'type': 'start', 'message': 'ğŸ”§ Default æ¨¡å¼ï¼šé–‹å§‹è™•ç†ä»»å‹™...'}

        yield f"data: {json.dumps(start_event, ensure_ascii=False)}\n\n"

        # è§£æè¦å‰‡
        rule_name = None
        query = message
        logger.info(f"ğŸ” é–‹å§‹è§£æè¦å‰‡:")
        logger.info(f"  - åŸå§‹ message: '{message}'")
        logger.info(f"  - message.startswith('/'): {message.startswith('/')}")

        if message.startswith('/'):
            parts = message[1:].split(' ', 1)
            logger.info(f"  - åˆ†å‰²å¾Œçš„ parts: {parts}")
            logger.info(f"  - parts é•·åº¦: {len(parts)}")
            if len(parts) >= 1:
                rule_name = parts[0]
                query = parts[1] if len(parts) > 1 else ""
                logger.info(f"  - è§£æå‡ºçš„ rule_name: '{rule_name}'")
                logger.info(f"  - è§£æå‡ºçš„ query: '{query}'")

        logger.info(f"ğŸ¯ æœ€çµ‚è§£æçµæœ:")
        logger.info(f"  - rule_name: '{rule_name}'")
        logger.info(f"  - query: '{query}'")

        if rule_name:
            rule_event = {'type': 'rule', 'rule_name': rule_name, 'message': f'ä½¿ç”¨è¦å‰‡: {rule_name}'}
            yield f"data: {json.dumps(rule_event, ensure_ascii=False)}\n\n"

        # ç™¼é€è™•ç†äº‹ä»¶
        processing_event = {'type': 'processing', 'message': 'æ­£åœ¨åŸ·è¡Œä»»å‹™...'}
        yield f"data: {json.dumps(processing_event, ensure_ascii=False)}\n\n"

        # ğŸ¯ **é—œéµæ­¥é©Ÿï¼šå‚³éé è™•ç†å¾Œçš„ä¸Šä¸‹æ–‡çµ¦ SupervisorAgent**
        logger.info("ğŸ”„ æ­¥é©Ÿ2: æº–å‚™ä¸Šä¸‹æ–‡æ•¸æ“šå‚³éçµ¦ SupervisorAgent")

        context = {
            "session_id": session_id,
            "context_data": final_context,  # é€™è£¡å·²ç¶“åŒ…å«äº† file_summary
            "current_time": __import__('datetime').datetime.now().isoformat()
        } if final_context else {
            "session_id": session_id,
            "current_time": __import__('datetime').datetime.now().isoformat()
        }

        # æª¢æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ summaryï¼ˆæ‡‰è©²å·²ç¶“åœ¨ final_context ä¸­ï¼‰
        if final_context and final_context.get('file_summary'):
            logger.info(f"ğŸ“‹ ç¢ºèªï¼šæ–‡ä»¶ Summary å·²åŒ…å«åœ¨ context_data ä¸­")
            logger.info(f"ğŸ“‹ Summary é¡å‹: {final_context['file_summary'].get('type', 'unknown')}")
        elif file_summary:
            # å‚™ç”¨æ–¹æ¡ˆï¼šç›´æ¥æ·»åŠ åˆ° context
            context["file_summary"] = file_summary
            logger.info(f"ğŸ“‹ å‚™ç”¨ï¼šæ–‡ä»¶ Summary å·²ç›´æ¥æ·»åŠ åˆ° context")

        # å°‡å·¥å…·åç¨±åˆ—è¡¨å‚³éçµ¦ Agentï¼Œè€Œä¸æ˜¯å‡½æ•¸å°è±¡
        tool_names = [tool.name for tool in available_tools]
        context["available_tool_names"] = tool_names

        logger.info(f"ğŸ”„ æ­¥é©Ÿ3: æº–å‚™èª¿ç”¨ SupervisorAgentï¼Œå·¥å…·æ•¸é‡: {len(available_tools)}")

        # ç²å–agentå¯¦ä¾‹ä¸¦è¨­ç½®streamå›èª¿
        agent = get_agent(session_id, stream_callback)

        # åŸ·è¡Œagentï¼Œstreamå›èª¿æœƒè‡ªå‹•è™•ç†å·¥å…·åŸ·è¡Œçµæœ
        result = await agent.run(query, rule_id=rule_name, context=context, available_tools=available_tools)

        # è½‰æ›numpyé¡å‹ä»¥é¿å…åºåˆ—åŒ–å•é¡Œ
        result = convert_numpy_types(result)

        # ç™¼é€æ‰€æœ‰å·¥å…·åŸ·è¡Œäº‹ä»¶
        for event_data in stream_events:
            if event_data['type'] == 'tool_result':
                tool_event = {
                    'type': 'tool_execution',
                    'tool_name': event_data['tool_name'],
                    'parameters': event_data['parameters'],
                    'execution_time': event_data['execution_time'],
                    'result': event_data['wrapped_result']
                }
                tool_event = convert_numpy_types(tool_event)
                yield f"data: {json.dumps(tool_event, ensure_ascii=False)}\n\n"

        # ç™¼é€å·¥å…·ä½¿ç”¨äº‹ä»¶
        tools_used = result.get('tools_used', [])
        if tools_used:
            tools_event = {'type': 'tools', 'message': f'ä½¿ç”¨äº†å·¥å…·: {", ".join(tools_used)}'}
            tools_event = convert_numpy_types(tools_event)
            yield f"data: {json.dumps(tools_event, ensure_ascii=False)}\n\n"

        # ç™¼é€å…§å®¹äº‹ä»¶
        content_event = {
            'type': 'content',
            'content': result.get('response', ''),
            'execution_time': result.get('execution_time', 0),
            'tools_used': tools_used
        }
        content_event = convert_numpy_types(content_event)
        yield f"data: {json.dumps(content_event, ensure_ascii=False)}\n\n"

        # ç™¼é€å®Œæˆäº‹ä»¶
        complete_event = {
            'type': 'complete',
            'message': 'ä»»å‹™åŸ·è¡Œå®Œæˆ',
            'success': result.get('success', True)
        }
        complete_event = convert_numpy_types(complete_event)
        yield f"data: {json.dumps(complete_event, ensure_ascii=False)}\n\n"

    except Exception as e:
        logger.error(f"æµå¼éŸ¿æ‡‰ç”Ÿæˆå¤±æ•—: {e}")
        error_event = {'type': 'error', 'message': f'è™•ç†å¤±æ•—: {str(e)}'}
        json_str = json.dumps(error_event, ensure_ascii=False)
        yield f"data: {json_str}\n\n"

    finally:
        # ç™¼é€çµæŸæ¨™è¨˜
        yield "data: [DONE]\n\n"


@router.post("/stream")
async def stream_chat(request: StreamRequest):
    """æµå¼èŠå¤©æ¥å£"""
    try:
        logger.info(f"æ”¶åˆ°æµå¼èŠå¤©è«‹æ±‚: {request.message[:100]}...")
        logger.info(f"  - user_id: {request.user_id}")
        logger.info(f"  - context_data: {request.context_data}")
        logger.info(f"  - page_data: {request.page_data}")

        # ğŸ” åˆ¤æ–·è«‹æ±‚é¡å‹ä¸¦é¸æ“‡å°æ‡‰çš„è™•ç†æ–¹å¼
        request_type = _determine_request_type(request.context_data, request.page_data)
        logger.info(f"ğŸ¯ è«‹æ±‚é¡å‹: {request_type}")

        return StreamingResponse(
            generate_stream_response(request.message, None, request.session_id, request.context_data, request.page_data, request_type),
            media_type="text/event-stream; charset=utf-8",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Content-Type": "text/event-stream; charset=utf-8",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
                "Access-Control-Allow-Methods": "*",
            }
        )

    except Exception as e:
        logger.error(f"æµå¼èŠå¤©å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/status")
async def get_agent_status():
    """ç²å– Agent ç‹€æ…‹"""
    try:
        agent = get_agent()
        rules = agent.parser.list_rules()
        
        return {
            "status": "running",
            "rules_count": len(rules),
            "available_rules": rules
        }
    except Exception as e:
        logger.error(f"ç²å–ç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))