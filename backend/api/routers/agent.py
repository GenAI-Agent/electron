"""
Agent API è·¯ç”±

è™•ç†èˆ‡ Agent ç›¸é—œçš„è«‹æ±‚ï¼Œåªæä¾›æµå¼æ¥å£ã€‚
"""

import json
from typing import AsyncGenerator, Dict, Any, Optional
from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

from supervisor_agent.core.supervisor_agent import SupervisorAgent

# æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘ä»¥å°å…¥å·¥å…·
import os
import sys
from pathlib import Path
current_dir = Path(__file__).parent
src_dir = current_dir.parent.parent / "src"
sys.path.insert(0, str(src_dir))

# å°å…¥ LangChain å…¼å®¹çš„æœ¬åœ°æ–‡ä»¶å·¥å…·
from supervisor_agent.tools.langchain_local_file_tools import get_langchain_local_file_tools
from supervisor_agent.utils.logger import get_logger

logger = get_logger(__name__)


# å·¥å…·è½‰æ›å‡½æ•¸å·²ç§»é™¤ï¼Œç›´æ¥ä½¿ç”¨ LangChain å·¥å…·

async def _preprocess_file(file_path: str, session_id: str) -> dict:
    """
    çœŸæ­£çš„æ–‡ä»¶é è™•ç†å‡½æ•¸

    Args:
        file_path: æ–‡ä»¶è·¯å¾‘
        session_id: æœƒè©±ID

    Returns:
        æ–‡ä»¶ summary å­—å…¸ï¼Œå¦‚æœå¤±æ•—è¿”å› None
    """
    logger.info(f"ğŸ”§ [_preprocess_file] é–‹å§‹åŸ·è¡Œæ–‡ä»¶é è™•ç†")
    logger.info(f"ğŸ“¥ è¼¸å…¥åƒæ•¸: file_path='{file_path}', session_id='{session_id}'")

    try:
        import os
        from pathlib import Path

        # æ­¥é©Ÿ1: å‰µå»º session ç›®éŒ„
        logger.info(f"ğŸ“‹ æ­¥é©Ÿ1: å‰µå»º session ç›®éŒ„")
        session_dir = os.path.join(os.getcwd(), 'temp', session_id)
        os.makedirs(session_dir, exist_ok=True)
        logger.info(f"âœ“ Session ç›®éŒ„: {session_dir}")

        # æ­¥é©Ÿ2: æª¢æŸ¥æ˜¯å¦å·²æœ‰ summary
        logger.info(f"ğŸ“‹ æ­¥é©Ÿ2: æª¢æŸ¥å·²å­˜åœ¨çš„ summary")
        summary_file = os.path.join(session_dir, 'file_summary.json')
        if os.path.exists(summary_file):
            logger.info(f"ğŸ“ ç™¼ç¾å·²å­˜åœ¨çš„ summary æ–‡ä»¶: {summary_file}")
            with open(summary_file, 'r', encoding='utf-8') as f:
                existing_summary = json.load(f)
            logger.info(f"âœ… [_preprocess_file] ä½¿ç”¨å·²å­˜åœ¨çš„ summary")
            return existing_summary

        # æ­¥é©Ÿ3: æª¢æŸ¥æ–‡ä»¶å­˜åœ¨æ€§å’ŒåŸºæœ¬ä¿¡æ¯
        logger.info(f"ğŸ“‹ æ­¥é©Ÿ3: æª¢æŸ¥æ–‡ä»¶åŸºæœ¬ä¿¡æ¯")
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

        file_size = os.path.getsize(file_path)
        file_extension = Path(file_path).suffix.lower()
        logger.info(f"âœ“ æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {file_size} bytes")
        logger.info(f"âœ“ æ–‡ä»¶æ“´å±•å: {file_extension}")

        # æ­¥é©Ÿ4: å°å…¥è™•ç†å·¥å…·
        logger.info(f"ğŸ“‹ æ­¥é©Ÿ4: å°å…¥è™•ç†å·¥å…·")
        from tools.local_file_tools import local_file_tools
        from tools.data_analysis_tools import data_analysis_tools
        logger.info(f"âœ“ å·¥å…·å°å…¥å®Œæˆ")

        # æ­¥é©Ÿ5: æ ¹æ“šæ–‡ä»¶é¡å‹é¸æ“‡è™•ç†æ–¹å¼
        logger.info(f"ğŸ“‹ æ­¥é©Ÿ5: æ ¹æ“šæ–‡ä»¶é¡å‹é¸æ“‡è™•ç†æ–¹å¼")
        if file_extension in ['.csv', '.json', '.xlsx', '.xls']:
            # æ•¸æ“šæ–‡ä»¶è™•ç†
            logger.info("ğŸ“Š è­˜åˆ¥ç‚ºæ•¸æ“šæ–‡ä»¶ï¼Œé–‹å§‹æ•¸æ“šè™•ç†")
            try:
                data_info = await data_analysis_tools.get_data_info(file_path, session_id)
                if data_info.get('success'):
                    summary = {
                        'type': 'data',
                        'file_path': file_path,
                        'file_extension': file_extension,
                        'file_size': file_size,
                        'data_info': data_info,
                        'processed_at': __import__('datetime').datetime.now().isoformat(),
                        'session_id': session_id
                    }
                    logger.info(f"âœ… æ•¸æ“šæ–‡ä»¶è™•ç†æˆåŠŸ: {data_info.get('data_shape', 'unknown')}")
                else:
                    raise Exception(f"æ•¸æ“šæ–‡ä»¶è™•ç†å¤±æ•—: {data_info}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ•¸æ“šæ–‡ä»¶è™•ç†å¤±æ•—: {e}ï¼Œå˜—è©¦æ–‡æœ¬è™•ç†")
                return await _process_as_text_file(file_path, session_id, session_dir)
        else:
            # æ–‡æœ¬æ–‡ä»¶è™•ç†
            logger.info("ğŸ“„ è­˜åˆ¥ç‚ºæ–‡æœ¬æ–‡ä»¶ï¼Œé–‹å§‹æ–‡æœ¬è™•ç†")
            return await _process_as_text_file(file_path, session_id, session_dir)

        # æ­¥é©Ÿ6: ä¿å­˜ summary åˆ°æ–‡ä»¶
        logger.info(f"ğŸ“‹ æ­¥é©Ÿ6: ä¿å­˜ summary åˆ°æ–‡ä»¶")
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ’¾ Summary å·²ä¿å­˜åˆ°: {summary_file}")
        logger.info(f"ğŸ“¤ Summary å…§å®¹å‰300å­—ç¬¦: {str(summary)[:300]}")
        logger.info(f"âœ… [_preprocess_file] åŸ·è¡Œå®Œæˆ")
        return summary

    except Exception as e:
        logger.error(f"âŒ [_preprocess_file] åŸ·è¡Œå¤±æ•—: {e}")
        return None

async def _process_as_text_file(file_path: str, session_id: str, session_dir: str) -> dict:
    """è™•ç†æ–‡æœ¬æ–‡ä»¶"""
    try:
        import os
        from pathlib import Path
        from tools.local_file_tools import local_file_tools

        # ç”Ÿæˆæ–‡æœ¬æ‘˜è¦
        summary_result = await local_file_tools.read_file_with_summary(file_path, session_id)
        if summary_result.get('success'):
            summary = {
                'type': 'text',
                'file_path': file_path,
                'file_extension': Path(file_path).suffix.lower(),
                'text_summary': summary_result,
                'processed_at': __import__('datetime').datetime.now().isoformat(),
                'session_id': session_id
            }

            # ä¿å­˜åˆ°æ–‡ä»¶
            summary_file = os.path.join(session_dir, 'file_summary.json')
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… æ–‡æœ¬æ–‡ä»¶è™•ç†æˆåŠŸ: {summary_result.get('file_info', {}).get('lines', 'unknown')} è¡Œ")
            return summary
        else:
            raise Exception(f"æ–‡æœ¬æ‘˜è¦ç”Ÿæˆå¤±æ•—: {summary_result}")

    except Exception as e:
        logger.error(f"âŒ æ–‡æœ¬æ–‡ä»¶è™•ç†å¤±æ•—: {e}")
        # æœ€å¾Œå˜—è©¦ç›´æ¥è®€å–
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            lines = content.split('\n')
            summary = {
                'type': 'raw_text',
                'file_path': file_path,
                'file_extension': Path(file_path).suffix.lower(),
                'content': content[:1000],  # åªä¿å­˜å‰1000å­—ç¬¦
                'char_count': len(content),
                'line_count': len(lines),
                'processed_at': __import__('datetime').datetime.now().isoformat(),
                'session_id': session_id
            }

            # ä¿å­˜åˆ°æ–‡ä»¶
            summary_file = os.path.join(session_dir, 'file_summary.json')
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… ç›´æ¥è®€å–æ–‡ä»¶æˆåŠŸ: {len(content)} å­—ç¬¦, {len(lines)} è¡Œ")
            return summary

        except Exception as raw_error:
            logger.error(f"âŒ ç›´æ¥è®€å–æ–‡ä»¶ä¹Ÿå¤±æ•—: {raw_error}")
            return None

def _determine_request_type(context_data: dict, page_data: dict) -> str:
    """
    åˆ¤æ–·è«‹æ±‚é¡å‹

    Args:
        context_data: ä¸Šä¸‹æ–‡æ•¸æ“š (local file)
        page_data: é é¢æ•¸æ“š (web)

    Returns:
        è«‹æ±‚é¡å‹: 'local_file', 'web', 'default'
    """
    if context_data and context_data.get('type') == 'file':
        return 'local_file'
    elif page_data:
        return 'web'
    else:
        return 'default'

async def _load_session_summary(session_id: str) -> dict:
    """
    è¼‰å…¥ session ä¸­çš„æ–‡ä»¶ summary

    Args:
        session_id: æœƒè©±ID

    Returns:
        æ–‡ä»¶ summary å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
    """
    try:
        import os
        session_dir = os.path.join(os.getcwd(), 'temp', session_id)
        summary_file = os.path.join(session_dir, 'file_summary.json')

        if os.path.exists(summary_file):
            logger.info(f"ğŸ“ è¼‰å…¥ session summary: {summary_file}")
            with open(summary_file, 'r', encoding='utf-8') as f:
                summary = json.load(f)
            logger.info(f"âœ… Session summary è¼‰å…¥æˆåŠŸï¼Œé¡å‹: {summary.get('type', 'unknown')}")
            return summary
        else:
            logger.info(f"ğŸ“ Session summary ä¸å­˜åœ¨: {summary_file}")
            return None
    except Exception as e:
        logger.error(f"âŒ è¼‰å…¥ session summary å¤±æ•—: {e}")
        return None

async def _update_session_summary(session_id: str, updated_summary: dict) -> bool:
    """
    æ›´æ–° session ä¸­çš„æ–‡ä»¶ summary

    Args:
        session_id: æœƒè©±ID
        updated_summary: æ›´æ–°å¾Œçš„ summary

    Returns:
        æ˜¯å¦æ›´æ–°æˆåŠŸ
    """
    try:
        import os
        session_dir = os.path.join(os.getcwd(), 'temp', session_id)
        os.makedirs(session_dir, exist_ok=True)
        summary_file = os.path.join(session_dir, 'file_summary.json')

        # æ·»åŠ æ›´æ–°æ™‚é–“æˆ³
        updated_summary['last_updated'] = __import__('datetime').datetime.now().isoformat()

        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(updated_summary, f, ensure_ascii=False, indent=2)

        logger.info(f"âœ… Session summary å·²æ›´æ–°: {summary_file}")
        return True
    except Exception as e:
        logger.error(f"âŒ æ›´æ–° session summary å¤±æ•—: {e}")
        return False

router = APIRouter()

# å…¨å±€ agent å¯¦ä¾‹
_agent_instance = None


def get_agent() -> SupervisorAgent:
    """ç²å– Agent å¯¦ä¾‹"""
    global _agent_instance

    if _agent_instance is None:
        # å‰µå»ºæ–°å¯¦ä¾‹ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
        from pathlib import Path
        rules_dir = Path(__file__).parent.parent.parent / "data" / "rules"
        logger.info(f"ğŸ”§ å‰µå»ºæ–° Agent å¯¦ä¾‹ï¼Œè¦å‰‡ç›®éŒ„: {rules_dir}")
        _agent_instance = SupervisorAgent(str(rules_dir))

    return _agent_instance

def set_agent(agent: SupervisorAgent):
    """è¨­ç½® Agent å¯¦ä¾‹"""
    global _agent_instance
    _agent_instance = agent
    logger.info("âœ… Agent å¯¦ä¾‹å·²è¨­ç½®")


class StreamRequest(BaseModel):
    """æµå¼è«‹æ±‚æ¨¡å‹"""
    message: str = Field(..., description="ç”¨æˆ¶æ¶ˆæ¯")
    user_id: str = Field(default="default_user", description="ç”¨æˆ¶ID")
    session_id: str = Field(default="default_session", description="æœƒè©±ID")
    context_data: Optional[Dict[str, Any]] = Field(default=None, description="ä¸Šä¸‹æ–‡è³‡æ–™ï¼ˆé é¢æˆ–æ–‡ä»¶ï¼‰")
    page_data: Optional[Dict[str, Any]] = Field(default=None, description="ç•¶å‰é é¢è³‡æ–™ï¼ˆå‘å¾Œå…¼å®¹ï¼‰")


async def generate_stream_response(message: str, agent: SupervisorAgent, session_id: str = "default_session", context_data: dict = None, page_data: dict = None, request_type: str = 'default') -> AsyncGenerator[str, None]:
    """ç”Ÿæˆæµå¼éŸ¿æ‡‰"""
    try:
        logger.info(f"ğŸš€ é–‹å§‹ç”Ÿæˆæµå¼éŸ¿æ‡‰")
        logger.info(f"  - message: {message}")
        logger.info(f"  - session_id: {session_id}")
        logger.info(f"  - context_data: {context_data}")
        logger.info(f"  - page_data: {page_data}")
        logger.info(f"  - request_type: {request_type}")

        # ğŸ¯ æ ¹æ“šè«‹æ±‚é¡å‹é¸æ“‡å·¥å…·é›†å’Œè™•ç†æ–¹å¼
        available_tools = []
        file_summary = None
        final_context = None

        if request_type == 'local_file':
            logger.info("ğŸ“ LOCAL FILE æ¨¡å¼ - Session è¨˜æ†¶ç³»çµ±")
            available_tools = get_langchain_local_file_tools()

            # ğŸ§  **æ­¥é©Ÿ1ï¼šè¼‰å…¥ Session ä¸­çš„ Summary (è¨˜æ†¶ç³»çµ±)**
            logger.info("ğŸ§  æ­¥é©Ÿ1: è¼‰å…¥ Session è¨˜æ†¶ä¸­çš„æ–‡ä»¶ Summary")
            session_summary = await _load_session_summary(session_id)

            if session_summary:
                logger.info("âœ… æ‰¾åˆ° Session è¨˜æ†¶ä¸­çš„ Summaryï¼Œä½¿ç”¨ç¾æœ‰è¨˜æ†¶")
                file_summary = session_summary
                summary_preview = str(file_summary)[:300]
                logger.info(f"ï¿½ Session Summary å‰300å­—ç¬¦: {summary_preview}")
            else:
                # ï¿½ğŸ”„ **æ­¥é©Ÿ2ï¼šå¦‚æœæ²’æœ‰ Summaryï¼ŒåŸ·è¡Œåˆå§‹æ–‡ä»¶é è™•ç†**
                if context_data and context_data.get('file_path'):
                    logger.info("ğŸ”„ æ­¥é©Ÿ2: Session ä¸­ç„¡ Summaryï¼ŒåŸ·è¡Œåˆå§‹æ–‡ä»¶é è™•ç†")
                    file_path = context_data.get('file_path')
                    file_summary = await _preprocess_file(file_path, session_id)

                    if file_summary:
                        logger.info(f"âœ… åˆå§‹æ–‡ä»¶é è™•ç†å®Œæˆï¼ŒSummary å·²å­˜å…¥ Session è¨˜æ†¶")
                        summary_preview = str(file_summary)[:300]
                        logger.info(f"ğŸ“„ æ–°å»º Summary å‰300å­—ç¬¦: {summary_preview}")
                    else:
                        logger.error("âŒ åˆå§‹æ–‡ä»¶é è™•ç†å¤±æ•—")
                        file_summary = None
                else:
                    logger.error("âŒ æ²’æœ‰æä¾› file_path ä¸” Session ä¸­ç„¡ Summary")
                    file_summary = None

            # ğŸ¯ **å°‡ Summary æ·»åŠ åˆ° context_data ä¸­ (æ°¸é åŒ…å«æœ€æ–°çš„ Session è¨˜æ†¶)**
            final_context = context_data.copy() if context_data else {}
            if file_summary:
                final_context['file_summary'] = file_summary
                logger.info("âœ… Session Summary å·²æ·»åŠ åˆ° context_dataï¼Œä½œç‚º SupervisorAgent çš„é»˜èªè¼¸å…¥")
            else:
                logger.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„ Summary")

        elif request_type == 'web':
            logger.info("ğŸŒ WEB æ¨¡å¼ - ä½¿ç”¨ Web Tools")
            # TODO: æ·»åŠ  Web Tools
            available_tools = []  # æš«æ™‚ç‚ºç©ºï¼Œç­‰å¾…å¯¦ç¾ Web Tools
            final_context = page_data
            logger.info(f"  - ä½¿ç”¨ä¸Šä¸‹æ–‡: {json.dumps(final_context, ensure_ascii=False, indent=2)}")

        else:
            logger.info("ğŸ”§ DEFAULT æ¨¡å¼ - ä½¿ç”¨é»˜èªå·¥å…·é›†")
            available_tools = get_langchain_local_file_tools()
            final_context = context_data or page_data
            if final_context:
                logger.info(f"  - ä½¿ç”¨ä¸Šä¸‹æ–‡: {json.dumps(final_context, ensure_ascii=False, indent=2)}")
            else:
                logger.info(f"  - ç„¡ä¸Šä¸‹æ–‡æ•¸æ“š")

        logger.info(f"ğŸ”§ é¸æ“‡çš„å·¥å…·æ•¸é‡: {len(available_tools)}")

        # ç™¼é€é–‹å§‹äº‹ä»¶
        if request_type == 'local_file':
            start_event = {'type': 'start', 'message': 'ğŸ“ Local File æ¨¡å¼ï¼šæ–‡ä»¶é è™•ç†å·²å®Œæˆï¼Œé–‹å§‹åˆ†æ...'}
        elif request_type == 'web':
            start_event = {'type': 'start', 'message': 'ğŸŒ Web æ¨¡å¼ï¼šé–‹å§‹è™•ç†ç¶²é å…§å®¹...'}
        else:
            start_event = {'type': 'start', 'message': 'ğŸ”§ Default æ¨¡å¼ï¼šé–‹å§‹è™•ç†ä»»å‹™...'}

        yield f"data: {json.dumps(start_event, ensure_ascii=False)}\n\n"

        # è§£æè¦å‰‡
        rule_name = None
        query = message
        logger.info(f"ğŸ” é–‹å§‹è§£æè¦å‰‡:")
        logger.info(f"  - åŸå§‹ message: '{message}'")
        logger.info(f"  - message.startswith('/'): {message.startswith('/')}")

        if message.startswith('/'):
            parts = message[1:].split(' ', 1)
            logger.info(f"  - åˆ†å‰²å¾Œçš„ parts: {parts}")
            logger.info(f"  - parts é•·åº¦: {len(parts)}")
            if len(parts) >= 1:
                rule_name = parts[0]
                query = parts[1] if len(parts) > 1 else ""
                logger.info(f"  - è§£æå‡ºçš„ rule_name: '{rule_name}'")
                logger.info(f"  - è§£æå‡ºçš„ query: '{query}'")

        logger.info(f"ğŸ¯ æœ€çµ‚è§£æçµæœ:")
        logger.info(f"  - rule_name: '{rule_name}'")
        logger.info(f"  - query: '{query}'")

        if rule_name:
            rule_event = {'type': 'rule', 'rule_name': rule_name, 'message': f'ä½¿ç”¨è¦å‰‡: {rule_name}'}
            yield f"data: {json.dumps(rule_event, ensure_ascii=False)}\n\n"

        # ç™¼é€è™•ç†äº‹ä»¶
        processing_event = {'type': 'processing', 'message': 'æ­£åœ¨åŸ·è¡Œä»»å‹™...'}
        yield f"data: {json.dumps(processing_event, ensure_ascii=False)}\n\n"

        # ğŸ¯ **é—œéµæ­¥é©Ÿï¼šå‚³éé è™•ç†å¾Œçš„ä¸Šä¸‹æ–‡çµ¦ SupervisorAgent**
        logger.info("ğŸ”„ æ­¥é©Ÿ2: æº–å‚™ä¸Šä¸‹æ–‡æ•¸æ“šå‚³éçµ¦ SupervisorAgent")

        context = {
            "session_id": session_id,
            "context_data": final_context,  # é€™è£¡å·²ç¶“åŒ…å«äº† file_summary
            "current_time": __import__('datetime').datetime.now().isoformat()
        } if final_context else {
            "session_id": session_id,
            "current_time": __import__('datetime').datetime.now().isoformat()
        }

        # æª¢æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ summaryï¼ˆæ‡‰è©²å·²ç¶“åœ¨ final_context ä¸­ï¼‰
        if final_context and final_context.get('file_summary'):
            logger.info(f"ğŸ“‹ ç¢ºèªï¼šæ–‡ä»¶ Summary å·²åŒ…å«åœ¨ context_data ä¸­")
            logger.info(f"ğŸ“‹ Summary é¡å‹: {final_context['file_summary'].get('type', 'unknown')}")
        elif file_summary:
            # å‚™ç”¨æ–¹æ¡ˆï¼šç›´æ¥æ·»åŠ åˆ° context
            context["file_summary"] = file_summary
            logger.info(f"ğŸ“‹ å‚™ç”¨ï¼šæ–‡ä»¶ Summary å·²ç›´æ¥æ·»åŠ åˆ° context")

        # å°‡å·¥å…·åç¨±åˆ—è¡¨å‚³éçµ¦ Agentï¼Œè€Œä¸æ˜¯å‡½æ•¸å°è±¡
        tool_names = [tool.name for tool in available_tools]
        context["available_tool_names"] = tool_names

        logger.info(f"ğŸ”„ æ­¥é©Ÿ3: æº–å‚™èª¿ç”¨ SupervisorAgentï¼Œå·¥å…·æ•¸é‡: {len(available_tools)}")

        result = await agent.run(query, rule_id=rule_name, context=context, available_tools=available_tools)

        # ç™¼é€å·¥å…·ä½¿ç”¨äº‹ä»¶
        tools_used = result.get('tools_used', [])
        if tools_used:
            tools_event = {'type': 'tools', 'message': f'ä½¿ç”¨äº†å·¥å…·: {", ".join(tools_used)}'}
            yield f"data: {json.dumps(tools_event, ensure_ascii=False)}\n\n"

        # ç™¼é€å…§å®¹äº‹ä»¶
        content_event = {
            'type': 'content',
            'content': result.get('response', ''),
            'execution_time': result.get('execution_time', 0),
            'tools_used': tools_used
        }
        yield f"data: {json.dumps(content_event, ensure_ascii=False)}\n\n"

        # ç™¼é€å®Œæˆäº‹ä»¶
        complete_event = {
            'type': 'complete',
            'message': 'ä»»å‹™åŸ·è¡Œå®Œæˆ',
            'success': result.get('success', True)
        }
        yield f"data: {json.dumps(complete_event, ensure_ascii=False)}\n\n"

    except Exception as e:
        logger.error(f"æµå¼éŸ¿æ‡‰ç”Ÿæˆå¤±æ•—: {e}")
        error_event = {'type': 'error', 'message': f'è™•ç†å¤±æ•—: {str(e)}'}
        json_str = json.dumps(error_event, ensure_ascii=False)
        yield f"data: {json_str}\n\n"

    finally:
        # ç™¼é€çµæŸæ¨™è¨˜
        yield "data: [DONE]\n\n"


@router.post("/stream")
async def stream_chat(request: StreamRequest):
    """æµå¼èŠå¤©æ¥å£"""
    try:
        logger.info(f"æ”¶åˆ°æµå¼èŠå¤©è«‹æ±‚: {request.message[:100]}...")
        logger.info(f"  - message: {request.message}")
        logger.info(f"  - user_id: {request.user_id}")
        logger.info(f"  - context_data: {request.context_data}")
        logger.info(f"  - page_data: {request.page_data}")

        # ğŸ” åˆ¤æ–·è«‹æ±‚é¡å‹ä¸¦é¸æ“‡å°æ‡‰çš„è™•ç†æ–¹å¼
        request_type = _determine_request_type(request.context_data, request.page_data)
        logger.info(f"ğŸ¯ è«‹æ±‚é¡å‹: {request_type}")

        agent = get_agent()

        return StreamingResponse(
            generate_stream_response(request.message, agent, request.session_id, request.context_data, request.page_data, request_type),
            media_type="text/event-stream; charset=utf-8",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Content-Type": "text/event-stream; charset=utf-8",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
                "Access-Control-Allow-Methods": "*",
            }
        )

    except Exception as e:
        logger.error(f"æµå¼èŠå¤©å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/status")
async def get_agent_status():
    """ç²å– Agent ç‹€æ…‹"""
    try:
        agent = get_agent()
        rules = agent.parser.list_rules()
        
        return {
            "status": "running",
            "rules_count": len(rules),
            "available_rules": rules
        }
    except Exception as e:
        logger.error(f"ç²å–ç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))